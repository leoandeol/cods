{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f9098e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from typing import Any, List, Optional, Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e68af07",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SNCFDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A PyTorch Dataset for the SNCF traffic light state dataset.\n",
    "\n",
    "    This version correctly handles:\n",
    "    1. Split files that contain full, absolute paths to images.\n",
    "    2. Label files that contain multiple bounding boxes (one per line).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, root: str, split: str, transforms: Optional[callable] = None):\n",
    "        \"\"\"\n",
    "        Initializes the SNCFDataset.\n",
    "\n",
    "        Args:\n",
    "            root (str): The root directory of the dataset. This is used to find\n",
    "                        the labels and classes.txt file.\n",
    "            split (str): The name of the split to load (e.g., 'train', 'calib').\n",
    "            transforms (callable, optional): A function/transform.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.root = root\n",
    "        self.split = split\n",
    "        self.transforms = transforms\n",
    "\n",
    "        # The labels directory is still found relative to the root\n",
    "        self.labels_dir = os.path.join(self.root, \"labels\")\n",
    "        self.classes_path = os.path.join(self.root, \"classes.txt\")\n",
    "\n",
    "        self.classes = self._load_classes()\n",
    "\n",
    "        # Load the split file which contains absolute paths to images\n",
    "        split_file_path = os.path.join(self.root, f\"{split}.txt\")\n",
    "        if not os.path.exists(split_file_path):\n",
    "            raise FileNotFoundError(f\"Split file not found: {split_file_path}\")\n",
    "\n",
    "        with open(split_file_path, \"r\") as f:\n",
    "            # self.image_files now contains absolute paths, e.g., '/path/to/images/file.jpg'\n",
    "            self.image_files = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "        # image ids are just the file names witout extensions or path\n",
    "        self.image_ids = [\n",
    "            os.path.splitext(os.path.basename(img_path))[0] for img_path in self.image_files\n",
    "        ]\n",
    "        \n",
    "        #TODO(leo): to satisfy rthe lib\n",
    "        self.NAMES = self.classes\n",
    "\n",
    "    def _load_classes(self) -> dict:\n",
    "        \"\"\"Loads class names from classes.txt.\"\"\"\n",
    "        with open(self.classes_path, \"r\") as f:\n",
    "            classes_raw = f.read().splitlines()\n",
    "            classes_raw = [c.split(\" \") for c in classes_raw if len(c) > 0]\n",
    "        return {int(c[0]): \" \".join(c[1:]) for c in classes_raw}\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"Returns the total number of images in the dataset for the current split.\"\"\"\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Tuple[Any, Any, Any, Any]:\n",
    "        \"\"\"\n",
    "        Retrieves an item from the dataset at the specified index.\n",
    "        \"\"\"\n",
    "        img_path = self.image_files[idx]\n",
    "\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        w, h = img.size\n",
    "\n",
    "        # To find the label, we still need the base filename (e.g., 'image.jpg')\n",
    "        base_img_filename = os.path.basename(img_path)\n",
    "        label_name = os.path.splitext(base_img_filename)[0] + \".txt\"\n",
    "\n",
    "        # Construct the absolute path to the label file\n",
    "        label_path = os.path.join(self.labels_dir, label_name)\n",
    "\n",
    "        target = self._load_target(label_path, h, w)\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            # Your transform function must accept both image and target\n",
    "            # img, target = self.transforms(img, target)\n",
    "            img = self.transforms(img)\n",
    "\n",
    "        image_size = img.size\n",
    "\n",
    "        return img_path, image_size, img, target\n",
    "\n",
    "    def _load_target(self, label_path: str, height: int, width: int) -> dict:\n",
    "        \"\"\"\n",
    "        Loads and processes a label file, handling multiple bounding boxes (lines).\n",
    "        \"\"\"\n",
    "        # --- MODIFICATION START ---\n",
    "        # Initialize lists to hold all boxes and labels for a single image.\n",
    "        boxes = []\n",
    "        labels = []\n",
    "\n",
    "        if not os.path.exists(label_path):\n",
    "            # Return empty lists if a label file doesn't exist for an image\n",
    "            return {\"boxes\": boxes, \"labels\": labels}\n",
    "\n",
    "        with open(label_path, \"r\") as f:\n",
    "            # Iterate over each line in the file, as each line is a new bounding box.\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                if not line:\n",
    "                    continue\n",
    "\n",
    "                label_data = line.split(\" \")\n",
    "\n",
    "                # Basic validation for a valid YOLO format line\n",
    "                if len(label_data) < 5:\n",
    "                    continue\n",
    "\n",
    "                class_id = label_data[0]\n",
    "                box_coords = np.array([float(x) for x in label_data[1:5]])\n",
    "\n",
    "                # Denormalize coordinates\n",
    "                box_coords = box_coords * np.array([width, height, width, height])\n",
    "\n",
    "                # Convert (center_x, center_y, w, h) to (x_min, y_min, x_max, y_max)\n",
    "                x_min = box_coords[0] - box_coords[2] / 2\n",
    "                y_min = box_coords[1] - box_coords[3] / 2\n",
    "                x_max = box_coords[0] + box_coords[2] / 2\n",
    "                y_max = box_coords[1] + box_coords[3] / 2\n",
    "\n",
    "                boxes.append([x_min, y_min, x_max, y_max])\n",
    "                labels.append(int(class_id))  # self.classes[class_id])\n",
    "\n",
    "        # The target dictionary now contains a list of boxes and a list of labels.\n",
    "        return {\"boxes\": boxes, \"labels\": labels}\n",
    "        # --- MODIFICATION END ---\n",
    "\n",
    "    def _collate_fn(self, batch):\n",
    "        return list([list(x) for x in zip(*batch)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd4718ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loading complete.\n",
      "------------------------------\n",
      "Training dataset size:   9047\n",
      "Validation dataset size: 1292\n",
      "Calibration dataset size:1292\n",
      "Test dataset size:       1294\n",
      "------------------------------\n",
      "\n",
      "First test sample path: /datasets/shared_datasets/SNCF/DATASET_etat_feu/images/EdPCfoF681.jpg\n",
      "First test sample target: {'boxes': [[np.float64(487.0003976), np.float64(332.999856), np.float64(530.0003704), np.float64(400.999824)]], 'labels': [23]}\n"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "trans = transforms.Compose(\n",
    "    [\n",
    "        # transforms.ToTensor(), #\n",
    "    ]\n",
    ")\n",
    "dataset_root_path = \"/datasets/shared_datasets/SNCF/DATASET_etat_feu\"\n",
    "\n",
    "# 1. Instantiate the training dataset\n",
    "# Used for training your model\n",
    "train_dataset = SNCFDataset(root=dataset_root_path, split=\"train\", transforms=trans)\n",
    "\n",
    "# 2. Instantiate the validation dataset\n",
    "# Used for monitoring training and hyperparameter tuning\n",
    "val_dataset = SNCFDataset(root=dataset_root_path, split=\"val\", transforms=trans)\n",
    "\n",
    "# 3. Instantiate the calibration dataset\n",
    "# A hold-out set used ONLY for calibrating your conformal predictor\n",
    "calib_dataset = SNCFDataset(root=dataset_root_path, split=\"calib\", transforms=trans)\n",
    "\n",
    "# 4. Instantiate the test dataset\n",
    "# The final hold-out set used ONLY for evaluating the final, calibrated model\n",
    "test_dataset = SNCFDataset(root=dataset_root_path, split=\"test\", transforms=trans)\n",
    "\n",
    "\n",
    "# --- Verification ---\n",
    "print(\"Dataset loading complete.\")\n",
    "print(\"-\" * 30)\n",
    "print(f\"Training dataset size:   {len(train_dataset)}\")\n",
    "print(f\"Validation dataset size: {len(val_dataset)}\")\n",
    "print(f\"Calibration dataset size:{len(calib_dataset)}\")\n",
    "print(f\"Test dataset size:       {len(test_dataset)}\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Example of accessing a sample from the test set\n",
    "if len(test_dataset) > 0:\n",
    "    img_path, _, _, target = test_dataset[0]\n",
    "    print(f\"\\nFirst test sample path: {img_path}\")\n",
    "    print(f\"First test sample target: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cdd42ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cods.od.models import YOLOModel\n",
    "\n",
    "model = YOLOModel(\n",
    "    model_name=\"./runs/detect/yolov8_sncf_augmented_training4/weights/best.pt\",\n",
    "    pretrained=True,\n",
    "    is_coco=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5cc603",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "File ./saved_predictions/faf9ed9fd5e4d5c0f039db7dcbceb091940a5af4f7460f51cfcb2669badc946e.pkl does not exist\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions do not exist, building them...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 108/108 [02:27<00:00,  1.37s/it]\n",
      "File ./saved_predictions/aca3be2ceb05fca84a3bbe930edf46bca483c8464a8dcf367e0e568b2bd7bb97.pkl does not exist\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions do not exist, building them...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 77/108 [02:10<00:55,  1.80s/it]"
     ]
    }
   ],
   "source": [
    "preds_cal = model.build_predictions(\n",
    "    calib_dataset,\n",
    "    dataset_name=\"sncf\",\n",
    "    split_name=\"cal\",\n",
    "    batch_size=12,\n",
    "    collate_fn=calib_dataset._collate_fn,  # TODO: make this a default for COCO\n",
    "    shuffle=False,\n",
    "    force_recompute=False,\n",
    "    deletion_method=\"nms\",\n",
    ")\n",
    "preds_test = model.build_predictions(\n",
    "    test_dataset,\n",
    "    dataset_name=\"sncf\",\n",
    "    split_name=\"test\",\n",
    "    batch_size=12,\n",
    "    collate_fn=test_dataset._collate_fn,\n",
    "    shuffle=False,\n",
    "    force_recompute=False,\n",
    "    deletion_method=\"nms\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f783b643",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cods.od.cp import ODConformalizer\n",
    "\n",
    "conf = ODConformalizer(\n",
    "    backend=\"auto\",\n",
    "    guarantee_level=\"image\",\n",
    "    matching_function=\"mix\",\n",
    "    multiple_testing_correction=None,\n",
    "    confidence_method=\"box_count_threshold\",\n",
    "    localization_method=\"pixelwise\",\n",
    "    localization_prediction_set=\"additive\",\n",
    "    classification_method=\"binary\",\n",
    "    classification_prediction_set=\"lac\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b169e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = conf.calibrate(\n",
    "    preds_cal,\n",
    "    alpha_confidence=0.02,\n",
    "    alpha_localization=0.05,\n",
    "    alpha_classification=0.05,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db801717",
   "metadata": {},
   "outputs": [],
   "source": [
    "conformal_preds = conf.conformalize(preds_test, parameters=parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_val = conf.evaluate(\n",
    "    preds_test,\n",
    "    parameters=parameters,\n",
    "    conformalized_predictions=conformal_preds,\n",
    "    include_confidence_in_global=False,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
