{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%load_ext line_profiler\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/leo.andeol/.cache/torch/hub/facebookresearch_detr_main\n",
      "/home/leo.andeol/envs/cods_13/cods/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/leo.andeol/envs/cods_13/cods/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(data) = 5000\n",
      "len(data_cal) = 400\n",
      "len(data_val) = 400\n"
     ]
    }
   ],
   "source": [
    "from cods.od.data import MSCOCODataset\n",
    "from cods.od.models import YOLOModel, DETRModel\n",
    "import logging\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"  # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = (\n",
    "    \"1\"  # chose the GPU. If only one, then \"0\"\n",
    ")\n",
    "\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "# set [COCO_PATH] to the directory to your local copy of the COCO dataset\n",
    "COCO_PATH = \"/datasets/shared_datasets/coco/\"\n",
    "\n",
    "data = MSCOCODataset(root=COCO_PATH, split=\"val\")\n",
    "\n",
    "calibration_ratio = (\n",
    "    0.5  # set 0.5 to use 50% for calibration and 50% for testing\n",
    ")\n",
    "\n",
    "use_smaller_subset = True  # TODO: Temp\n",
    "\n",
    "if use_smaller_subset:\n",
    "    data_cal, data_val = data.split_dataset(\n",
    "        calibration_ratio, shuffle=False, n_calib_test=800\n",
    "    )\n",
    "else:\n",
    "    data_cal, data_val = data.split_dataset(calibration_ratio, shuffle=False)\n",
    "\n",
    "# model and weights are downloaded from https://github.com/facebookresearch/detr\n",
    "model = DETRModel(model_name=\"detr_resnet50\", pretrained=True, device=\"cuda:0\")\n",
    "#model = YOLOModel(model_name=\"yolov8x.pt\", pretrained=True, device=\"cpu\")\n",
    "\n",
    "\n",
    "print(f\"{len(data) = }\")\n",
    "print(f\"{len(data_cal) = }\")\n",
    "print(f\"{len(data_val) = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions already exist, loading them...\n",
      "Predictions already exist, loading them...\n"
     ]
    }
   ],
   "source": [
    "preds_cal = model.build_predictions(\n",
    "    data_cal,\n",
    "    dataset_name=\"mscoco\",\n",
    "    split_name=\"cal\",\n",
    "    batch_size=12,\n",
    "    collate_fn=data._collate_fn,  # TODO: make this a default for COCO\n",
    "    shuffle=False,\n",
    "    force_recompute=False,  # False,\n",
    "    deletion_method=\"nms\",\n",
    ")\n",
    "preds_val = model.build_predictions(\n",
    "    data_val,\n",
    "    dataset_name=\"mscoco\",\n",
    "    split_name=\"test\",\n",
    "    batch_size=12,\n",
    "    collate_fn=data._collate_fn,\n",
    "    shuffle=False,\n",
    "    force_recompute=False,  # False,\n",
    "    deletion_method=\"nms\",\n",
    ")\n",
    "\n",
    "# Filter the preds_cal and preds_val with confidence below 0.001\n",
    "\n",
    "\n",
    "def filter_preds(preds, confidence_threshold=0.001):\n",
    "    filters = [\n",
    "        conf > confidence_threshold\n",
    "        if (conf > confidence_threshold).any()\n",
    "        else conf.argmin(0)[None]\n",
    "        for conf in preds.confidences\n",
    "    ]\n",
    "    preds.pred_boxes = [pbs[f] for pbs, f in zip(preds.pred_boxes, filters)]\n",
    "    preds.pred_cls = [pcs[f] for pcs, f in zip(preds.pred_cls, filters)]\n",
    "    preds.confidences = [\n",
    "        conf[f] for conf, f in zip(preds.confidences, filters)\n",
    "    ]\n",
    "    return preds\n",
    "\n",
    "\n",
    "preds_cal = filter_preds(preds_cal)\n",
    "preds_val = filter_preds(preds_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cods.od.utils import match_predictions_to_true_boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avant\n",
    "1.05 s ± 56.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching = [[70], [10], [0], [70], [10], [10], [6], [66], [10], [70], [2], [30], [10], [70], [10], [10], [70], [10], [7]], len=19\n",
      "Matching = [[12], [45], [33], [33], [1], [33], [0], [7], [33], [8], [33], [33], [10], [8]], len=14\n",
      "Matching = [[0], [2], [1], [3], [2], [44], [6]], len=7\n"
     ]
    }
   ],
   "source": [
    "matching = match_predictions_to_true_boxes(preds_cal,\"hausdorff\", class_factor=None)\n",
    "for i in range(3):  \n",
    "    print(f\"Matching = {matching[i]}, len={len(matching[i])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63.4 ms ± 93.5 μs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit \n",
    "match_predictions_to_true_boxes(preds_cal,\"hausdorff\", class_factor=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-09 s\n",
      "\n",
      "Total time: 0.0686834 s\n",
      "File: /home/leo.andeol/envs/cods_13/cods/cods/od/utils.py\n",
      "Function: match_predictions_to_true_boxes at line 366\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   366                                           def match_predictions_to_true_boxes(\n",
      "   367                                               preds,\n",
      "   368                                               distance_function,\n",
      "   369                                               overload_confidence_threshold=None,\n",
      "   370                                               verbose=False,\n",
      "   371                                               hungarian=False,\n",
      "   372                                               idx=None,\n",
      "   373                                               class_factor: float = 0.25,\n",
      "   374                                           ) -> None:\n",
      "   375                                               \"\"\"Matching predictions to true boxes. Done in place, modifies the preds object.\"\"\"\n",
      "   376                                               # TODO(leo): switch to gpu\n",
      "   377         1        581.0    581.0      0.0      dist_iou = lambda x, y: -f_iou(x, y)\n",
      "   378         1        150.0    150.0      0.0      dist_generalized_iou = lambda x, y: -generalized_iou(x, y)\n",
      "   379         1        380.0    380.0      0.0      DISTANCE_FUNCTIONS = {\n",
      "   380         1        110.0    110.0      0.0          \"iou\": dist_iou,\n",
      "   381         1        100.0    100.0      0.0          \"giou\": dist_generalized_iou,\n",
      "   382         1        241.0    241.0      0.0          \"hausdorff\": assymetric_hausdorff_distance_old,\n",
      "   383         1         80.0     80.0      0.0          \"lac\": None,\n",
      "   384         1         90.0     90.0      0.0          \"mix\": None,\n",
      "   385                                               }\n",
      "   386                                           \n",
      "   387         1        130.0    130.0      0.0      if verbose and distance_function is None:\n",
      "   388                                                   print(\"Using default:  asymmetric Hausdorff distance\")\n",
      "   389                                           \n",
      "   390         1        331.0    331.0      0.0      if distance_function not in DISTANCE_FUNCTIONS:\n",
      "   391                                                   raise ValueError(\n",
      "   392                                                       f\"Distance function {distance_function} not supported, must be one of {DISTANCE_FUNCTIONS.keys()}\",\n",
      "   393                                                   )\n",
      "   394                                           \n",
      "   395         1        191.0    191.0      0.0      f_dist = DISTANCE_FUNCTIONS[distance_function]\n",
      "   396                                           \n",
      "   397         1         90.0     90.0      0.0      if overload_confidence_threshold is not None:\n",
      "   398                                                   conf_thr = overload_confidence_threshold\n",
      "   399         1        291.0    291.0      0.0      elif preds.confidence_threshold is not None:\n",
      "   400                                                   conf_thr = preds.confidence_threshold\n",
      "   401                                               else:\n",
      "   402         1        141.0    141.0      0.0          conf_thr = 0\n",
      "   403                                           \n",
      "   404         1       2274.0   2274.0      0.0      device = preds.pred_boxes[0].device\n",
      "   405                                               # once, not per-iter\n",
      "   406                                               # preds.pred_boxes = [x.to(device, dtype=torch.float16).contiguous() for x in preds.pred_boxes]\n",
      "   407                                               # preds.true_boxes = [x.to(device, dtype=torch.float16).contiguous() for x in preds.true_boxes]\n",
      "   408                                               # if your class losses are used in the mix:\n",
      "   409                                               # preds.pred_cls   = [x.to(device) for x in preds.pred_cls]   # keep int/long as-is\n",
      "   410                                               # preds.true_cls   = [x.to(device) for x in preds.true_cls]\n",
      "   411                                           \n",
      "   412                                               # To only update it on a single image\n",
      "   413         2      18175.0   9087.5      0.0      with torch.no_grad():\n",
      "   414         1        130.0    130.0      0.0          if idx is not None:\n",
      "   415                                                       masks = [preds.confidences[idx] >= conf_thr]\n",
      "   416                                                       pred_boxess = [preds.pred_boxes[idx][masks[0]]]\n",
      "   417                                                       preds_clss = [preds.pred_cls[idx][masks[0]]]\n",
      "   418                                                       true_boxess = [preds.true_boxes[idx]]\n",
      "   419                                                       true_clss = [preds.true_cls[idx]]\n",
      "   420                                                   else:\n",
      "   421         1    2015665.0    2e+06      2.9              masks = [c >= conf_thr for c in preds.confidences]\n",
      "   422         1   11950190.0    1e+07     17.4              pred_boxess = [b[m] for b, m in zip(preds.pred_boxes, masks)]\n",
      "   423         1   11467508.0    1e+07     16.7              preds_clss = [c[m] for c, m in zip(preds.pred_cls, masks)]\n",
      "   424         1        932.0    932.0      0.0              true_boxess = preds.true_boxes\n",
      "   425         1        351.0    351.0      0.0              true_clss = preds.true_cls\n",
      "   426                                           \n",
      "   427         1       1293.0   1293.0      0.0      torch.set_grad_enabled(False)\n",
      "   428         1        190.0    190.0      0.0      all_matching_tensors = []\n",
      "   429         1        280.0    280.0      0.0      use_giou = distance_function == \"giou\"\n",
      "   430         1        180.0    180.0      0.0      use_haus = distance_function == \"hausdorff\"\n",
      "   431         1        131.0    131.0      0.0      use_lac = distance_function == \"lac\"\n",
      "   432         1        130.0    130.0      0.0      use_mix = distance_function == \"mix\"\n",
      "   433                                           \n",
      "   434       402     791476.0   1968.8      1.2      for pred_boxes, true_boxes, pred_cls, true_cls in tqdm(\n",
      "   435         1        521.0    521.0      0.0          zip(pred_boxess, true_boxess, preds_clss, true_clss),\n",
      "   436         1        140.0    140.0      0.0          disable=not verbose,\n",
      "   437                                               ):\n",
      "   438       400    1086361.0   2715.9      1.6          if len(true_boxes) == 0:\n",
      "   439         4        761.0    190.2      0.0              matching = []\n",
      "   440       396     350410.0    884.9      0.5          elif len(pred_boxes) == 0:\n",
      "   441                                                       matching = [[]] * len(true_boxes)\n",
      "   442                                                   else:\n",
      "   443                                                       # with torch.cuda.amp.autocast(enabled=True):\n",
      "   444       396    3831943.0   9676.6      5.6              true_boxes = true_boxes.clone()\n",
      "   445       396    2115202.0   5341.4      3.1              pred_boxes = pred_boxes.clone()\n",
      "   446       396      48872.0    123.4      0.1              if use_haus:\n",
      "   447       792   26642455.0  33639.5     38.8                  distance_matrix = assymetric_hausdorff_distance(\n",
      "   448       396      31601.0     79.8      0.0                      true_boxes,\n",
      "   449       396      31397.0     79.3      0.0                      pred_boxes,\n",
      "   450                                                           )\n",
      "   451                                                       elif use_lac:\n",
      "   452                                                           distance_matrix = f_lac(true_cls, pred_cls)\n",
      "   453                                                       elif use_mix:\n",
      "   454                                                           l_lac = f_lac(true_cls, pred_cls)\n",
      "   455                                                           l_ass = assymetric_hausdorff_distance(true_boxes, pred_boxes)\n",
      "   456                                                           scale = torch.clamp(l_ass.max(), min=1e-12)\n",
      "   457                                                           l_ass = l_ass / scale\n",
      "   458                                                           distance_matrix = class_factor * l_lac + (1 - class_factor) * l_ass\n",
      "   459                                                       elif use_giou:\n",
      "   460                                                           distance_matrix = vectorized_generalized_iou(\n",
      "   461                                                               true_boxes,\n",
      "   462                                                               pred_boxes,\n",
      "   463                                                           )\n",
      "   464                                                       else:\n",
      "   465                                                           raise NotImplementedError(\n",
      "   466                                                               \"Only hausdorff and lac are supported\",\n",
      "   467                                                           )\n",
      "   468       396      88450.0    223.4      0.1              if hungarian:\n",
      "   469                                                           # TODO(leo): to test\n",
      "   470                                                           row_ind, col_ind = linear_sum_assignment(distance_matrix)\n",
      "   471                                                           matching = [[]] * len(true_boxes)\n",
      "   472                                                           for x, y in zip(row_ind, col_ind):\n",
      "   473                                                               if x < len(true_boxes) and y < len(pred_boxes):\n",
      "   474                                                                   matching[x] = [y]\n",
      "   475                                                       else:\n",
      "   476       396    3756366.0   9485.8      5.5                  matching = torch.argmin(distance_matrix, dim=1).unsqueeze(1)\n",
      "   477                                           \n",
      "   478       400     171975.0    429.9      0.3          all_matching_tensors.append(matching)\n",
      "   479                                           \n",
      "   480         2    4230907.0    2e+06      6.2      all_matching = [\n",
      "   481         1        100.0    100.0      0.0          m.cpu().tolist() if isinstance(m, torch.Tensor) else m for m in all_matching_tensors\n",
      "   482                                               ]\n",
      "   483         1        191.0    191.0      0.0      if idx is not None:\n",
      "   484                                                   return all_matching[0]\n",
      "   485         1      43803.0  43803.0      0.1      preds.matching = all_matching\n",
      "   486         1        120.0    120.0      0.0      return all_matching"
     ]
    }
   ],
   "source": [
    "%lprun -f match_predictions_to_true_boxes match_predictions_to_true_boxes(preds_cal,\"hausdorff\", class_factor=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Après"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching = [[70], [10], [0], [70], [10], [10], [6], [66], [10], [70], [2], [30], [10], [70], [10], [10], [70], [10], [7]], len=19\n",
      "Matching = [[12], [45], [33], [33], [1], [33], [0], [7], [33], [8], [33], [33], [10], [8]], len=14\n",
      "Matching = [[0], [2], [1], [3], [2], [44], [6]], len=7\n"
     ]
    }
   ],
   "source": [
    "matching = match_predictions_to_true_boxes(preds_cal,\"hausdorff\")\n",
    "for i in range(3):  \n",
    "    print(f\"Matching = {matching[i]}, len={len(matching[i])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63.5 ms ± 84.9 μs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit \n",
    "match_predictions_to_true_boxes(preds_cal,\"hausdorff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-09 s\n",
      "\n",
      "Total time: 0.0677583 s\n",
      "File: /home/leo.andeol/envs/cods_13/cods/cods/od/utils.py\n",
      "Function: match_predictions_to_true_boxes at line 366\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   366                                           def match_predictions_to_true_boxes(\n",
      "   367                                               preds,\n",
      "   368                                               distance_function,\n",
      "   369                                               overload_confidence_threshold=None,\n",
      "   370                                               verbose=False,\n",
      "   371                                               hungarian=False,\n",
      "   372                                               idx=None,\n",
      "   373                                               class_factor: float = 0.25,\n",
      "   374                                           ) -> None:\n",
      "   375                                               \"\"\"Matching predictions to true boxes. Done in place, modifies the preds object.\"\"\"\n",
      "   376                                               # TODO(leo): switch to gpu\n",
      "   377         1        541.0    541.0      0.0      dist_iou = lambda x, y: -f_iou(x, y)\n",
      "   378         1        231.0    231.0      0.0      dist_generalized_iou = lambda x, y: -generalized_iou(x, y)\n",
      "   379         1        310.0    310.0      0.0      DISTANCE_FUNCTIONS = {\n",
      "   380         1        110.0    110.0      0.0          \"iou\": dist_iou,\n",
      "   381         1         90.0     90.0      0.0          \"giou\": dist_generalized_iou,\n",
      "   382         1        140.0    140.0      0.0          \"hausdorff\": assymetric_hausdorff_distance_old,\n",
      "   383         1         81.0     81.0      0.0          \"lac\": None,\n",
      "   384         1         80.0     80.0      0.0          \"mix\": None,\n",
      "   385                                               }\n",
      "   386                                           \n",
      "   387         1        120.0    120.0      0.0      if verbose and distance_function is None:\n",
      "   388                                                   print(\"Using default:  asymmetric Hausdorff distance\")\n",
      "   389                                           \n",
      "   390         1        191.0    191.0      0.0      if distance_function not in DISTANCE_FUNCTIONS:\n",
      "   391                                                   raise ValueError(\n",
      "   392                                                       f\"Distance function {distance_function} not supported, must be one of {DISTANCE_FUNCTIONS.keys()}\",\n",
      "   393                                                   )\n",
      "   394                                           \n",
      "   395         1        160.0    160.0      0.0      f_dist = DISTANCE_FUNCTIONS[distance_function]\n",
      "   396                                           \n",
      "   397         1         90.0     90.0      0.0      if overload_confidence_threshold is not None:\n",
      "   398                                                   conf_thr = overload_confidence_threshold\n",
      "   399         1        251.0    251.0      0.0      elif preds.confidence_threshold is not None:\n",
      "   400                                                   conf_thr = preds.confidence_threshold\n",
      "   401                                               else:\n",
      "   402         1        130.0    130.0      0.0          conf_thr = 0\n",
      "   403                                           \n",
      "   404         1       2074.0   2074.0      0.0      device = preds.pred_boxes[0].device\n",
      "   405                                               # once, not per-iter\n",
      "   406                                               # preds.pred_boxes = [x.to(device, dtype=torch.float16).contiguous() for x in preds.pred_boxes]\n",
      "   407                                               # preds.true_boxes = [x.to(device, dtype=torch.float16).contiguous() for x in preds.true_boxes]\n",
      "   408                                               # if your class losses are used in the mix:\n",
      "   409                                               # preds.pred_cls   = [x.to(device) for x in preds.pred_cls]   # keep int/long as-is\n",
      "   410                                               # preds.true_cls   = [x.to(device) for x in preds.true_cls]\n",
      "   411                                           \n",
      "   412                                               # To only update it on a single image\n",
      "   413         2      16191.0   8095.5      0.0      with torch.no_grad():\n",
      "   414         1        141.0    141.0      0.0          if idx is not None:\n",
      "   415                                                       masks = [preds.confidences[idx] >= conf_thr]\n",
      "   416                                                       pred_boxess = [preds.pred_boxes[idx][masks[0]]]\n",
      "   417                                                       preds_clss = [preds.pred_cls[idx][masks[0]]]\n",
      "   418                                                       true_boxess = [preds.true_boxes[idx]]\n",
      "   419                                                       true_clss = [preds.true_cls[idx]]\n",
      "   420                                                   else:\n",
      "   421         1    1990728.0    2e+06      2.9              masks = [c >= conf_thr for c in preds.confidences]\n",
      "   422         1   11901147.0    1e+07     17.6              pred_boxess = [b[m] for b, m in zip(preds.pred_boxes, masks)]\n",
      "   423         1   11462399.0    1e+07     16.9              preds_clss = [c[m] for c, m in zip(preds.pred_cls, masks)]\n",
      "   424         1        931.0    931.0      0.0              true_boxess = preds.true_boxes\n",
      "   425         1        501.0    501.0      0.0              true_clss = preds.true_cls\n",
      "   426                                           \n",
      "   427         1       1242.0   1242.0      0.0      torch.set_grad_enabled(False)\n",
      "   428         1        151.0    151.0      0.0      all_matching_tensors = []\n",
      "   429         1        260.0    260.0      0.0      use_giou = distance_function == \"giou\"\n",
      "   430         1        210.0    210.0      0.0      use_haus = distance_function == \"hausdorff\"\n",
      "   431         1        120.0    120.0      0.0      use_lac = distance_function == \"lac\"\n",
      "   432         1        110.0    110.0      0.0      use_mix = distance_function == \"mix\"\n",
      "   433                                           \n",
      "   434       402     724534.0   1802.3      1.1      for pred_boxes, true_boxes, pred_cls, true_cls in tqdm(\n",
      "   435         1        531.0    531.0      0.0          zip(pred_boxess, true_boxess, preds_clss, true_clss),\n",
      "   436         1        141.0    141.0      0.0          disable=not verbose,\n",
      "   437                                               ):\n",
      "   438       400    1060831.0   2652.1      1.6          if len(true_boxes) == 0:\n",
      "   439         4        792.0    198.0      0.0              matching = []\n",
      "   440       396     338959.0    856.0      0.5          elif len(pred_boxes) == 0:\n",
      "   441                                                       matching = [[]] * len(true_boxes)\n",
      "   442                                                   else:\n",
      "   443                                                       # with torch.cuda.amp.autocast(enabled=True):\n",
      "   444       396    3779261.0   9543.6      5.6              true_boxes = true_boxes.clone()\n",
      "   445       396    2073988.0   5237.3      3.1              pred_boxes = pred_boxes.clone()\n",
      "   446       396      43623.0    110.2      0.1              if use_haus:\n",
      "   447       792   26659836.0  33661.4     39.3                  distance_matrix = assymetric_hausdorff_distance(\n",
      "   448       396      32165.0     81.2      0.0                      true_boxes,\n",
      "   449       396      30789.0     77.8      0.0                      pred_boxes,\n",
      "   450                                                           )\n",
      "   451                                                       elif use_lac:\n",
      "   452                                                           distance_matrix = f_lac(true_cls, pred_cls)\n",
      "   453                                                       elif use_mix:\n",
      "   454                                                           l_lac = f_lac(true_cls, pred_cls)\n",
      "   455                                                           l_ass = assymetric_hausdorff_distance(true_boxes, pred_boxes)\n",
      "   456                                                           scale = torch.clamp(l_ass.max(), min=1e-12)\n",
      "   457                                                           l_ass = l_ass / scale\n",
      "   458                                                           distance_matrix = class_factor * l_lac + (1 - class_factor) * l_ass\n",
      "   459                                                       elif use_giou:\n",
      "   460                                                           distance_matrix = vectorized_generalized_iou(\n",
      "   461                                                               true_boxes,\n",
      "   462                                                               pred_boxes,\n",
      "   463                                                           )\n",
      "   464                                                       else:\n",
      "   465                                                           raise NotImplementedError(\n",
      "   466                                                               \"Only hausdorff and lac are supported\",\n",
      "   467                                                           )\n",
      "   468       396      86437.0    218.3      0.1              if hungarian:\n",
      "   469                                                           # TODO(leo): to test\n",
      "   470                                                           row_ind, col_ind = linear_sum_assignment(distance_matrix)\n",
      "   471                                                           matching = [[]] * len(true_boxes)\n",
      "   472                                                           for x, y in zip(row_ind, col_ind):\n",
      "   473                                                               if x < len(true_boxes) and y < len(pred_boxes):\n",
      "   474                                                                   matching[x] = [y]\n",
      "   475                                                       else:\n",
      "   476       396    3744266.0   9455.2      5.5                  matching = torch.argmin(distance_matrix, dim=1).unsqueeze(1)\n",
      "   477                                           \n",
      "   478       400     161167.0    402.9      0.2          all_matching_tensors.append(matching)\n",
      "   479                                           \n",
      "   480         2    3586851.0    2e+06      5.3      all_matching = [\n",
      "   481         1         90.0     90.0      0.0          m.cpu().tolist() if isinstance(m, torch.Tensor) else m for m in all_matching_tensors\n",
      "   482                                               ]\n",
      "   483         1        140.0    140.0      0.0      if idx is not None:\n",
      "   484                                                   return all_matching[0]\n",
      "   485         1      55115.0  55115.0      0.1      preds.matching = all_matching\n",
      "   486         1         90.0     90.0      0.0      return all_matching"
     ]
    }
   ],
   "source": [
    "%lprun -f match_predictions_to_true_boxes match_predictions_to_true_boxes(preds_cal,\"hausdorff\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from cods.od.utils import assymetric_hausdorff_distance, assymetric_hausdorff_distance_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbs = preds_cal.true_boxes[idx].clone()\n",
    "pbs = preds_cal.pred_boxes[idx].clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "matching1 = []\n",
    "distances1 = np.zeros((len(tbs), len(pbs)))\n",
    "true_boxes = tbs\n",
    "pred_boxes = pbs\n",
    "for i, true_box in enumerate(true_boxes):\n",
    "    distances = []\n",
    "    for j, pred_box in enumerate(pred_boxes):\n",
    "        dist = assymetric_hausdorff_distance_old(true_box, pred_box)\n",
    "        dist = (\n",
    "            dist.cpu().numpy()\n",
    "            if isinstance(dist, torch.Tensor)\n",
    "            else dist\n",
    "        )\n",
    "        distances.append(dist)  # .cpu().numpy())\n",
    "        distances1[i, j] = dist\n",
    "    \n",
    "    matching1.append([np.argmin(distances)])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_boxes = tbs\n",
    "pred_boxes = pbs\n",
    "\n",
    "distances2 = assymetric_hausdorff_distance(true_boxes, pred_boxes)\n",
    "matching2 = torch.argmin(distances2, dim=1).cpu().numpy().reshape(-1, 1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x713cea5d2550>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(distances1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x713ce9b82850>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAChCAYAAABnAt39AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAALApJREFUeJztnXt0VfWZ97/nngshN8g5ScgNCCAgiCA0BVuVDJFx+oJ1rPo6HayrdaQwo6VdKvO2Um07sXXVsU55oXWs6HReUTvFaqsgFwlVASFCUUBuBknIDQIn95zr7/2D8cyEPM8uYZKTmHw/a+214Nn7+d33Pk/O+X33YzPGGBBCCCGExAn7QDeAEEIIIcMLBh+EEEIIiSsMPgghhBASVxh8EEIIISSuMPgghBBCSFxh8EEIIYSQuMLggxBCCCFxhcEHIYQQQuIKgw9CCCGExBXnQDfgYqLRKGpra5GSkgKbzTbQzSGEEELIJWCMQWtrK3JycmC3/5nvNkw/8fOf/9wUFBQYj8djZs+ebXbv3n1JftXV1QYADx48ePDgweMzeFRXV//Zz/p++ebjxRdfxIoVK7B27VrMmTMHTz75JMrKynDkyBFkZWVZ+qakpAAArsu6C067u9u5ltl5qt/5CQ7R3uWLqD62iPzNiqNL/8YlkmBEe9QTVX0cbXLboqOC8vUuvc3hLnnKHB7dxyhNs53xqD4p4/2i3e2Q6+kMudSygiG5/wF/guozYnS7XFZAX7IjR3SJ9nPnk1UfyNOJqDLOqVltalEjPAHRXn9IX/PuArm8zsYk1Sczr1m0W/UzLU0ez/N1I0W7LVFfT/ZGed24C1tVH4dDXoQdp+T6ASB7QqNorzuij6dnjDyeaUmdor3++Ci1LGen/JebrVBfA3a7vKCCp0eoPhrFV1aL9rMdeln+Y+miPbGoRfVxv5Eq2s/NCqs+jhblOSTfAhfOTZTXhzZmrq362mieLK+nhFr5WQMAnUXy8xZhi7/QlbZljzmnupw9IK9PW5G8bsJ1+n2bVCDPW9dxec4AIJwZEu2uRv0ZnVgvf+ZF9Ec0sv/Ycz7DkQDe3v9E7HPcin4JPp544gl84xvfwNe+9jUAwNq1a/GHP/wBv/rVr/DQQw9Z+n76U4vT7u4RfDhd+kg4PPKis1s8RG1hecDt0IMPowQfSNCDD3tYuSES5UVvd1s8+G3ylNkTLiP4SNCDD0eSfM7hlOtxBPWF7QgpbQ5YzGeS/OCzOyzqSZLnxqoeLfiAMs6OJPnGBgCnUo09waqfcnn2RCsfOciyd13GeCr1WAYfyrpxJCkPd+jBh9XYOJPlei5nPJ3JSv0W42w3yv2pjCWgf5BatVlD678D+n2r1eNI0qMCh1v2sSda9DOo3NMWv5Rr60MbM61dF9omz6f2OXDBRwkyLiP40OYG0OdAWzdRy/Usz5vVerInKp+FCRbPTo8ycXo34XTqz8JL2TLR5xtOg8EgKisrUVpa+l+V2O0oLS3Fzp07e1wfCATQ0tLS7SCEEELI0KXPg4+zZ88iEonA6/V2s3u9XtTX1/e4vry8HKmpqbEjL0//aYUQQgghn30GXGq7cuVKNDc3x47qavl3TkIIIYQMDfp8z8eoUaPgcDjQ0NDQzd7Q0ACfz9fjeo/HA49H+GHJmAvHfyPlnSq13pF73KL98IO5emOV3/sLf9ehupz4SqJenoJN21egYHm5ctL0so4LTr2XMkcVH6vq1bZZOJnLaJvqc1ljI5u1/lues/DR2myzrEc91et6LmcNaOvZas4uZz718dR9tHpUF4t2eXfL+woai6z6qZ1QXaBtMdP6bzn/yrnggTTVRX5yArZOff9E8XPnRXvDtfKGVwDoDMubJDvy5L0gEyv1jb3+K+UN2b7d+t6Wjwvlv7XHbNLn8+x0+SOyvtkr2gFgwrozcv0/kD87civ0/YKNrWmiPfOIvgg6R8szmnZC38PTlS7PdebeJtXHnKzpYbMbfd9Xj2sv+cpLxO12Y+bMmdi6dWvMFo1GsXXrVpSUlPR1dYQQQgj5jNEvapcVK1ZgyZIlmDVrFmbPno0nn3wS7e3tMfULIYQQQoYv/RJ83HbbbThz5gwefvhh1NfX46qrrsLGjRt7bEIlhBBCyPCj316vvnz5cixfvry/iieEEELIZ5QBV7sQQgghZHjB4IMQQgghcWXQZbX9lDMLCnu8Xvfclbq8yLg0/Z9FJcq5JkXGBQB2RUkUtXh7cu5bssQp6WM5R4etS5eLmRFy2z56QM8PcMUjch6C87N7Sp8/pevjDNGuibXGbD+rlmU7L9cf9WWqPvWfTxPtmVX6K33tEVliFhmrv1bY/3l5rMe+KMvfom49r0ZzUZpoz27QpXSns+Q2F/+bnIsEABzKS4DPP6i6YNRj8gLNrpfzpxxeJc8/AORvkm+CU3+h53PwbZF9zk3W//6pM3KOjLG/lV8vDwAR5dXv1Qvkto19Xb/X7AH5FfPuSos8LcpUFz37keoSmlog2huP5Iv2lvH6Q02TbT7wz8+rPsu3fVW033HNbtXnhRGzRfuEQv09TUvzt4t2uzJo3/LcppYFv2yu/gtNOAzc9bkK0b59bLHqc8voj0X7X6fuVX0e+O09on2yr1a0n/um/uz+6diNov3Zunmqz1WpPSWwALCxdrLq42+W13TjF/X8OpOWCfOm5fIQ4DcfhBBCCIkrDD4IIYQQElcYfBBCCCEkrjD4IIQQQkhcYfBBCCGEkLgyaNUuxn7huNimXy/vAC/4vb4z3B6Ud+bWf07eMQ8Aha/LKoRAuq6o0DhbMlq0W/XTJm/AR9abej8bv5gt2jMOt6s+6W8rCYVc8pKpWaQn8HO3jBLtdj3PEXJ+e0K0H71/rOqTWyEX6PvNUb1trfJO95oblARlFnfM+F/JypFgrpxQCwC8m+Td+f4J+hqMuOTd8d5N+hpolQUViI6T1VNWZbUrIqnCN3QVSihJHrjc/zip+nROyRHtNTfoajTvHlkNVfCGrGqpuUEfZ3tQXgOFL9arPlpmuaa/nKj7KHh3+kV7+lG9/84Ouf8uKA8OQE1s57L33sdh19UOmqrFrTzUbMozHbBI4GeRv9Bhk+t3WrRZ83EpdgComS/fn5OVjIw2i8yj2rxZtdmljKfdoh61DRbjaSvK62mLBIAjuk+39lzaZYQQQgghfQODD0IIIYTEFQYfhBBCCIkrDD4IIYQQElcYfBBCCCEkrjD4IIQQQkhcGbRSW0cQcFxk06RvAGAUfWryRxayuKAsSwstkBM6AYD7aJ1od43Uk02dv1qWmgZSlf5chtTWt7NN9ambKyfVCqTrMsNgqizPNQ65zUE9/xBgk31sFlLbriljRHs4VZf/BdIuXjEXSCiU+wIAqcdkuXHjHFnOaJy6XK1tspwoz9j1dZtcKydcO3ulnqkwqqi6Rx3Q10DjTHl9GqfcNu9uvayGa+T1NOK03k9tbpLdukQ9nCjfCKGRusxQqyfaIbctNNJKii/bQ16Lxa7dH9q9DqgJLpsnyRJtd4t+D0Q88j3tj+ryXITktjWHE3vt0xHSE7v5I3IbNKltNCjPJaB/FmhzBuj96Qjpa1Dz8Uf1Z2coRZ7QtpDs02lRvzZvWlmA3maresIhJRQI6h9G4fSebQuHL/37DH7zQQghhJC4wuCDEEIIIXGFwQchhBBC4gqDD0IIIYTEFQYfhBBCCIkrfa52+f73v49HHnmkm23ixIn46KOPelWOPWTguGgbuF3ZYQ0AnvEtor19kpy8DQCibrm8MTNqVR//PDlDV+JZWTkDAGeuluuJZsmJuCwTKkXkeDH3t+dUn9ar5V3OoRRdUZFU17tEQ66rz+v1t8i7r01En09nl7xrvmSavo7ea5sk2sOJsjoDALLeqBLt06bL/U9w6vN8fJ+cPKylSHXB+H9rFe3Nf6v/XWB3K4mjXtUVKudnKHPtkvuZ/ZYuG/DPkMcg7YTe5jMzZXvUJSePAwBPs9zPohmnVZ8qyAkOfbvktTZx+im1rM6wfN+cP6q3WcM/w0KGoWDfLdfv1qcZDTNlH39ETnYGALaQPG+tIf35MGG8rPo736UrZJqVNrgU2ZuxUFponwWOKfLnAAC0hOX+TEqTE0IC+hhYqYdyZ8hjoymBfMnyMwDQ563dQlXUoqhdkt36GmwKyc9Id7qeLLL+cz0VdJGAA9itunSjX6S2U6ZMwZYtW/6rEuegVfQSQgghJM70S1TgdDrh8yl5twkhhBAyrOmXPR/Hjh1DTk4Oxo4dizvvvBOnTulfbQYCAbS0tHQ7CCGEEDJ06fPgY86cOVi3bh02btyINWvWoKqqCtdeey1aW+XftcrLy5Gamho78vLy+rpJhBBCCBlE9HnwsXDhQtx6662YNm0aysrK8Prrr8Pv9+Oll14Sr1+5ciWam5tjR3V1dV83iRBCCCGDiH7fCZqWloYJEybg+PHj4nmPxwOPko+AEEIIIUOPfg8+2tracOLECXz1q1/tnV+uHQ5P9y9mwmN02Y/plKVHtV/Qu6glIXJsk+V6ABC9QraHUvQvkca+0inataRe9k4941o4Re7noX/U21z8C7mjwVRdNtqZ2bulkXe/nKANAKJyfix0+XT5X4dXtjd+V9etjuuU29A8XpfFHXpYTiJY/I/ymLUrcwYAzjxZtpq3VR/nw3+fLtrzN6guGLFPlvJZrYErnmoW7eE0WZZ3eJkyaQCyt8prvWG2fg+Me0n+2fXcFD0hY8M1cmKx3PIsvZ4WeQ2cWihLCV0/1scsoV4uy/95fQ3YovIamPx/9G90/dcWivaIRy6rfraeIGzMW/IzcvE3jqk+T+bK2t2yjA9Unx/U3STa5+cfVX0WpRwU7Vpv1o0pUcs6o8jnQ2f0Z8pN0/4k2jf6p6k+81MPyWUl6Z9Fj/+z/HqHL5TvEu0NAT1R4ZeS5fGsy0pTfWYlfyza2yO6PFejqV1/dua99EkPWzgawKW+VKPPf3b5zne+g4qKCpw8eRLvvvsubr75ZjgcDtxxxx19XRUhhBBCPoP0+TcfNTU1uOOOO9DU1ITRo0dj3rx52LVrF0aP1l/2RQghhJDhQ58HH+vXr+/rIgkhhBAyhGBuF0IIIYTEFQYfhBBCCIkrgzbpii1y4fjvmLAeK0Vt8s7wMW/LyakAwB6KivaGWfqu4Nw/yrucA+n6DvRQinyu3SsPv7EICe1Kd7J26j7+YlnRkH5Iz1CVfFh502xIVuLU3CIn3AMAd4s8N3Zd1IPMXXKyp+N360qH3O2yOiJjs7z7GwCMbZxo/+RGJRmexR1T/JScpC4wUU9E5n1XnuyALjZBxwJZoeN9V09I6J8qq2qiyrL1vqvXr63PnLd1BUAwQ07QlbVFV4GMqMsW7fUlujTfu0duXM7bAdF++gt6WfZgmmgv+L2eRBEReQ6a5ltkF1TIfLdetCfVZ6o+jg5ZWdWuqHAAIKw8V7u0xQEgoiS47IzoPu1R2cdtk5/DwbB8PwN6gk2bRbLKjqg819Ztlj8LAsYikegMuTytHqv6u5Rp61DaBQBdyjmrekLK3GjzDAAmqec9bZUs9GL4zQchhBBC4gqDD0IIIYTEFQYfhBBCCIkrDD4IIYQQElcYfBBCCCEkrjD4IIQQQkhcGbRS28QmA4e7u86oo0mXChmX3JXqBbrEzB6SfdIP6j6f3CjLtcIjdUlvwauyffSOWvlEp0UCvZFyIq6P/o+uzbziu7Js9fznx6g+XTP1hF8SuRvlOgDA1iJLek2G3ub6+bKkNvctXeKmqK1Rf7MspwUAf4kswRy7Tr4+6tLj9bpFspwyuUGWEgJAY6ncnwk/09eAvUtOevfRQ3KyLQAY/wt5fbqqm0T74R8omf0AjHtG7s/Jm2Q5LQDkbZHbfHqxLBsGgNaxcj3jXtaTGIaT5Hv6VJksPyx8TU76CAD2kDxmNQtk2TIAQFmDec8cVl3CV8hjULdAlhq36MsZuTtkeeqegJ5AL3ROnrf32wtVn84mWYp+ZKS+bvaMlPvpvvidCv+J/5zFM6hNnmf3Of3+rFT6c9Svp/5IdcnrY5xbf96N2SInUTxYKs+nv0seSwDYM0qet4PNclkA4IB835w4P0r1Od8sJ+SLtOqfudFPeiYrjFpIkC+G33wQQgghJK4w+CCEEEJIXGHwQQghhJC4wuCDEEIIIXGFwQchhBBC4sqgVbvYoga2i5Ih2aJ60hqjCQpsFolulJ3pyubrC+c0IYwukNF9onKjjbEoTPGBsein4qO2C7Dsj3y9hYNTWWZaXy6nfgBQkmcpeav+sx5l3Kz6o6CNp82iLO2UzWpslDVtLO6Pi++lGOoatKheG2fdxWJsrOqxKLCX9SgCAGu0Mbuce119QFmM52WMmda2kEVGRO25GoxafDwoPmElQdmfa4OE9XrW7LpPyMhKoIhFm8NR2ae3fQGAiJKR0ap+Lbmf1TgHlHmLXM7np9Vak9ZtL56b/OaDEEIIIXGFwQchhBBC4gqDD0IIIYTEFQYfhBBCCIkrDD4IIYQQEld6vWV3x44dePzxx1FZWYm6ujps2LABixcvjp03xmDVqlV4+umn4ff7MXfuXKxZswbFxcW9qifxbBhOZ7ibrb1Jzs8AAFGnvJM3kKnvMreHZZ+kM2HRDgDNxfKQ2UJ6HGcPyu+7D+VkiPaoR95hDQDONjlHhrGoP1gk50mxh6zy3lhpF3rSPiFTPecIynPgaezQ61emIJykj40mt9DKAgCjrIFwsjyeUZc+LnYlrYE9aLEDPCzXY1PyigBA60Qlt0hYX+udPjl/R3Knkl/HYj25as+KdltIz1ERSZDLs1qDNm1uRljkeLLLPnZlOEMj9EegQ8njY7WeVBVGeprq42xskesJyfk2bBb120NyA/a0yXmHAMBzVr6nDvv1PC1uxac+daTqU5lZKNqdirzQedYir4hTXjcJ8tIEABz0y/lQzjTpOZEOunyiPS9BT7ATHiF/Tp1uShPtwU69n3t98rydOmeRX0jhfJOeK8ful9vgbrNQyIR6fhaZ/szt0t7ejunTp2P16tXi+Z/85Cd46qmnsHbtWuzevRvJyckoKytDV5eeKIsQQgghw4def/OxcOFCLFy4UDxnjMGTTz6J7373u1i0aBEA4Pnnn4fX68Urr7yC22+//X/WWkIIIYR85unTPR9VVVWor69HaWlpzJaamoo5c+Zg586dok8gEEBLS0u3gxBCCCFDlz4NPurr6wEAXm/33wq9Xm/s3MWUl5cjNTU1duTl5fVlkwghhBAyyBhwtcvKlSvR3NwcO6qrqwe6SYQQQgjpR/o0+PD5LuwMbmho6GZvaGiInbsYj8eDkSNHdjsIIYQQMnTp08RyRUVF8Pl82Lp1K6666ioAQEtLC3bv3o2lS5f2qqyI2w7bRVK3iK60hZJ/B0ouH8tzmizQsjy7RfIwxcfV0Cxfn6B31NbeqdQvSykBwNXYKto7fR7Vp7dhacJZXc1k75K1gfaGc6qPscsSUDVBGgBXqyzZ68ywWDhKP7Xkgjar9aSogI3DQrZsV5L+afMMIOFMklKWfjt7zsoSOHUOHLLMEwBMkrLWLMbG2S4PaNRhJZtVEq6FLSTiWqI8ZWzsEYuyIlpZqosq9zYd+nwiVZZ6quvJ8pkmNyDdqcvaIwnyGKS4A6pPVHl0uN26DjjD1S7aHYo+OeKxkGErp8L6YxCpbnkOnG5d1q6NQbpT7gugrxuPMjbRiD6hmcqYJbh1SetIt/wsdnr0foYT5MUWDVm82sAunDPRS07i2Ovgo62tDcePH4/9v6qqCvv370dGRgby8/Nx//3344c//CGKi4tRVFSE733ve8jJyen2LhBCCCGEDF96HXzs3bsX119/fez/K1asAAAsWbIE69atwwMPPID29nbcc8898Pv9mDdvHjZu3IiEBIuQlBBCCCHDhl4HH9dddx2Msfg6zGbDo48+ikcfffR/1DBCCCGEDE0GXO1CCCGEkOEFgw9CCCGExJU+Vbv0JW25Djjc3XfTduZYZFRSEg0V/E53sQfkbbn1n9NVIPlvyjuJg2n6UEaVBFVnviAnOrLaza6pMLzb9J/CzsyVE8tlHNZ3bKe+3SCfcMr9rPnrArUsd4vcNntYSWoGwPeHT0T70b/X68mtkOvJeuWo6uPskhMe1s6TVQPG4o4p/mWdaA8UyAkEAcC7TVbinP3iGNUnoghErNZAW57c8GjR2F6Xde4qOamVdm8AQChJrj/ndydVn46pOaK9dp5+f3r3yCqA/Ddl1ULN9XpZ9qA8N4UvKfcGAChqm6YFeiIyjax3mkR76sd6IjRnu9z/spQPVJ/nfCWifW7GCdXnYLb87JrslV8mCQClKQdFu0vJlPdi9tVqWYEmOYlhp/xGBwDAvIzjoj0Y1W/qazOPifYbk/VnypPXLhbts7zyeJ7t0hO+laZ8KNpPZenPlKtS5HdlNQf0xI+1ifIrLjpG6PeHY2LPZ4eJBIAjqks3+M0HIYQQQuIKgw9CCCGExBUGH4QQQgiJKww+CCGEEBJXGHwQQgghJK4w+CCEEEJIXLEZq9eVDgAtLS1ITU1Fqe8eOO3dpW4tJbrMMuKWpZH18yzexhqSfTL/pCcCOz9ZtodH6kl7Cl6V29AxWpZ4RSzyvbk65LLOlOlJoNK3y6+218oCgPYcOS7VVGmOoFoU7Mq5hHN6BqIOr1y/JjUGgIiiJHO16v1s/rwsD019Rx6zcJK+NiJKBoH0I3qjaxfJ0sicV/WEa81FcrKn9it1qWvyAblxKTWK3Pwv9Qkt+H9y/TXX65LFpDot45rqgrYiuW0ZB/Q5CCXL59ry5YpSZSUlAH1Nd3j1+rWEZxmHLF4ToNBwjTye4RH6fZOzQz7X/DU5uSQAuF5LE+1Nc/Q2Z74nt621UHWBa3KLaLcpg+Z6U5fi+6fK/czdotdf81fyfeip0RNPBnLk+zM3T5ZBA0DwBa9ob7mpTbTbDunSaddV50V7x7E01SeSKbc54aTeT49fqd/i2TnqxT/1sIVNENs61qO5ufnPZqjnNx+EEEIIiSsMPgghhBASVxh8EEIIISSuMPgghBBCSFxh8EEIIYSQuDJoE8s1LiiAw919h753W616fcMNchKqG+fsV30iRt61/sdzM1SfG67bp57TaJ8my1dmpZ4U7RkOeVc0ANSF5KReo5z6bvbQTFmd8G6znuzq77zbRXuyTd5J7Y/qSYv80STR/qeOfNVn3gg5O1FTRE/CNM51RrRXdhWqPs2KRKZDmbPrUw6pZfkccqK+H9YuVH1Wjn5PtG+feoXqc2u67PPy+dmqzy3z9or2N1qnifbarjS1rM6HZSXOd7J2qT4Jyrp5qUlv87e9snTh8ZIFqs/izErRPtZ5TrSvPnO9WtbrO6+S67/xBdVHS5L2msUzReM/ct4U7R+HddXCmrk3iPYPfzFV9elU1Dv2JAuFjk3+6HB06Uqg5Fdk9UPXl/1yFbqoB87MTtHeOCtZ9UlKk5+rzgP6eAYz5b/P21/VM9i5o7JCJDejWbT7a/VnmuNkmmi3perjHD0j9yepTleudI6WywuNsFB25fYcA1skAOj5CLvBbz4IIYQQElcYfBBCCCEkrjD4IIQQQkhcYfBBCCGEkLjC4IMQQgghcYXBByGEEELiSq8Ty+3YsQOPP/44KisrUVdXhw0bNmDx4sWx83fddReee+65bj5lZWXYuHHjJZX/aWK5aX/7ox5S2/NX6k1NyJOlpllPyzJPAIi6ZBmRWS5LNgEg+sss0Z54Vk/EdfIvlSRlWbKPza7300TkeHHyw3Wqz+EfyrKwhGN6BrtkRZalqJPRdZOcNAoAOlrk/puILuPKfFeWc4792lHVZ987E0R7+mHVBaPebRTt9l92iPYEhywZBYCT64pFe2uRXv/4n38s2g/9ME/1sbllDeKEf9aTCx75O0WC6JTLKn5G7+exr8lSvqKXdG1k9QLZJ/OAvtY9frk8+30Nqk/NPlly79sll5W07LRaVmdYXoOdL+oyS42zJb1PLJe5W5azjjitl9U4U27zE3c9o/os3fa3ov3O2bp0endToWh3WOhj782rEO2aPPm+3XeoZUXPys8uT44sdweA2yfIMuwTHaNUn/xEObHbV9L2qD7f/Oh/i/asJPkzKqhl6wSwdMxbov25+rmqz1Uja0T767VTVJ8zzbLc1yo6SNzV0ycS6MLh//uP/ZNYrr29HdOnT8fq1avVa2688UbU1dXFjhde0HXxhBBCCBle9PolYwsXLsTChfpLkwDA4/HA57u0vw4CgQACgf/6i62lRf8LmhBCCCGfffplz8f27duRlZWFiRMnYunSpWhqalKvLS8vR2pqauzIy9O/biaEEELIZ58+Dz5uvPFGPP/889i6dSt+/OMfo6KiAgsXLkQkEhGvX7lyJZqbm2NHdXV1XzeJEEIIIYOIPs/tcvvtt8f+feWVV2LatGkYN24ctm/fjvnz5/e43uPxwOPRNz4SQgghZGjR74nlxo4di1GjRuH48eNi8KERSbQB7u5qiGiivsu7o1lOEBZ16ooKe1Demd3wx2zVJ+dcl2jvytCTE415S253u0/2MRbfR9nkL5DQdJ3+c1VmhTwGGQf1ZHTO08pPZVF5zGpSxur1N8tbpu1KXwBg1A5ZhbCvWFa0AMCY7fI4J1aeVH2abhwv2v1vy9cbizumeIu8yzxt7Gi9/lJZCpOlzBkARJSl5p+ir8Hs7UpZLjnpYMs4vaM+pSx7WJ/QXOUeSP5QV2l1TJHvw/o/5ur17JFVOo6AvG4/eVtPbmhXBD+FO3U1HCJyPY6gvgY0MvbI9XTlpao+eVvk5Gk5X5eTmgF6AjmvS99/d7IhU7TPKTyp+uQ4ZeWIG/KYJSTqCsL2RHl9Bk/rieWyp/pF+8FW/Xmf7ZZ9fA59rZ/7o7zfccoiea2f6dITy+U65HnL8ujJR70u2ScjUVbwAUBHUFZJtbbpCUNz3+ipFAxHArAQF3aj39/zUVNTg6amJmRn6xNMCCGEkOFDr7/5aGtrw/Hjx2P/r6qqwv79+5GRkYGMjAw88sgjuOWWW+Dz+XDixAk88MADGD9+PMrKyvq04YQQQgj5bNLr4GPv3r24/vrrY/9fsWIFAGDJkiVYs2YNDhw4gOeeew5+vx85OTlYsGABfvCDH3BfByGEEEIAXEbwcd1118HqpaibNm36HzWIEEIIIUMb5nYhhBBCSFxh8EEIIYSQuNLvUtvLJZwAmIu2idgSdHnTiNRO0Z64QpeLGSVLmjcqyw8BwHG93IZkm/5TVEdIlkDOzqgV7SOdcl8A4EwwRbSnuXQZVVTpZ2WTLjP8St77oj1B0R/6IwfVsprDcnK/Q226AqrkoROyPawnlstffFa0/6ld72dLWB63zogsPZuXdkwtK+cWWUr4RNUC1eeWnA9E+85zunT5f2X9SbS/2jhd9blptFzP1nNXiPamLl2yqCVcK8s9oPokKMnD/tAwVfW5L0/OCbX61PWiHQAWfOWQaB/rlmWrz9bqCbralft23lc+Un20xGpbGiepPnbIz46HHv29aD8Z1BOhPVst92e0XX9NgSdBvqe9Lr/qM84nj2eGW0/sNtouJz5U8nsiyaNLbSPp8t/NjlF6Yrssp/xZkO7Wn52jFZ8sh35/eK+TXxOQ6ZLHJmzxeeNVEllmunWprU+Zt0yPPjctCXLyz1BEb1vNX/VMshoJdAH6I7Ib/OaDEEIIIXGFwQchhBBC4gqDD0IIIYTEFQYfhBBCCIkrg27D6afvEIkEeuZQiXbKeVUAIOKSNzOFHbL9Ql3yTierDUB2JSGJzWLDaTgknwu65c1EAaeSVAJAMChvwgq4dB9tw2m4XR+bzjZ5g5pRNq51RvQNbV1huW2hdn1DWadTLk8rCwA63bJPoN1iPMPyXIei8pxp7QKADqe8NqzGuUsZZ8uxuRwfJS+S5hPu0h8N4bC8qU/rCwBA2XBqNTYdrX03nh0uuSyrMdPu2642fT1pG06t2qxtOG1vlcvqDOnjrNXTqpQFAJEO+bmqjb9VPUEtIQ6A1gS5DdqG00iHPmYRbY+ow2Ljv9KfYJu+BjqUHC4tRh9PbWwCysbeYECvX5u3gMUa7Ij2vp9amyMd+mehTfiMjgQv2KzeBRbzN5dyVRypqalBXp6eJI0QQgghg5fq6mqMGTPG8ppBF3xEo1HU1tYiJSUFNpsNLS0tyMvLQ3V1NUaOHDnQzYs77P/w7j/AMRju/Qc4Buz/Z6P/xhi0trYiJycHdrv1ro5B97OL3W4XI6aRI0cO6kHvb9j/4d1/gGMw3PsPcAzY/8Hf/9TU1Eu6jhtOCSGEEBJXGHwQQgghJK4M+uDD4/Fg1apV8Hg8f/7iIQj7P7z7D3AMhnv/AY4B+z/0+j/oNpwSQgghZGgz6L/5IIQQQsjQgsEHIYQQQuIKgw9CCCGExBUGH4QQQgiJKww+CCGEEBJXBnXwsXr1ahQWFiIhIQFz5szBe++9N9BN6jd27NiBL33pS8jJyYHNZsMrr7zS7bwxBg8//DCys7ORmJiI0tJSHDt2bGAa2w+Ul5fjmmuuQUpKCrKysrB48WIcOXKk2zVdXV1YtmwZMjMzMWLECNxyyy1oaGgYoBb3LWvWrMG0adNibzAsKSnBG2+8ETs/lPsu8dhjj8Fms+H++++P2Yb6GHz/+9+HzWbrdkyaNCl2fqj3HwBOnz6Nv/mbv0FmZiYSExNx5ZVXYu/evbHzQ/05WFhY2GMN2Gw2LFu2DMDQWgODNvh48cUXsWLFCqxatQrvv/8+pk+fjrKyMjQ2Ng500/qF9vZ2TJ8+HatXrxbP/+QnP8FTTz2FtWvXYvfu3UhOTkZZWRm6uvRMv58lKioqsGzZMuzatQubN29GKBTCggUL0N7eHrvmW9/6Fl577TW8/PLLqKioQG1tLb785S8PYKv7jjFjxuCxxx5DZWUl9u7dixtuuAGLFi3CwYMHAQztvl/Mnj178Itf/ALTpk3rZh8OYzBlyhTU1dXFjrfffjt2bqj3//z585g7dy5cLhfeeOMNHDp0CD/96U+Rnp4eu2aoPwf37NnTbf43b94MALj11lsBDLE1YAYps2fPNsuWLYv9PxKJmJycHFNeXj6ArYoPAMyGDRti/49Go8bn85nHH388ZvP7/cbj8ZgXXnhhAFrY/zQ2NhoApqKiwhhzob8ul8u8/PLLsWsOHz5sAJidO3cOVDP7lfT0dPOv//qvw6rvra2tpri42GzevNl88YtfNPfdd58xZnjM/6pVq8z06dPFc8Oh/w8++KCZN2+een44Pgfvu+8+M27cOBONRofcGhiU33wEg0FUVlaitLQ0ZrPb7SgtLcXOnTsHsGUDQ1VVFerr67uNR2pqKubMmTNkx6O5uRkAkJGRAQCorKxEKBTqNgaTJk1Cfn7+kBuDSCSC9evXo729HSUlJcOq78uWLcNNN93Ura/A8Jn/Y8eOIScnB2PHjsWdd96JU6dOARge/X/11Vcxa9Ys3HrrrcjKysKMGTPw9NNPx84Pt+dgMBjEr3/9a9x9992w2WxDbg0MyuDj7NmziEQi8Hq93exerxf19fUD1KqB49M+D5fxiEajuP/++zF37lxMnToVwIUxcLvdSEtL63btUBqDDz74ACNGjIDH48G9996LDRs2YPLkycOi7wCwfv16vP/++ygvL+9xbjiMwZw5c7Bu3Tps3LgRa9asQVVVFa699lq0trYOi/5//PHHWLNmDYqLi7Fp0yYsXboU//AP/4DnnnsOwPB7Dr7yyivw+/246667AAy9e8A50A0g5GKWLVuGDz/8sNvv3cOBiRMnYv/+/WhubsZvfvMbLFmyBBUVFQPdrLhQXV2N++67D5s3b0ZCQsJAN2dAWLhwYezf06ZNw5w5c1BQUICXXnoJiYmJA9iy+BCNRjFr1iz80z/9EwBgxowZ+PDDD7F27VosWbJkgFsXf5555hksXLgQOTk5A92UfmFQfvMxatQoOByOHrt4Gxoa4PP5BqhVA8enfR4O47F8+XL8/ve/x1tvvYUxY8bE7D6fD8FgEH6/v9v1Q2kM3G43xo8fj5kzZ6K8vBzTp0/Hz372s2HR98rKSjQ2NuLqq6+G0+mE0+lERUUFnnrqKTidTni93iE/BheTlpaGCRMm4Pjx48NiDWRnZ2Py5MndbFdccUXsp6fh9Bz85JNPsGXLFnz961+P2YbaGhiUwYfb7cbMmTOxdevWmC0ajWLr1q0oKSkZwJYNDEVFRfD5fN3Go6WlBbt37x4y42GMwfLly7FhwwZs27YNRUVF3c7PnDkTLper2xgcOXIEp06dGjJjcDHRaBSBQGBY9H3+/Pn44IMPsH///tgxa9Ys3HnnnbF/D/UxuJi2tjacOHEC2dnZw2INzJ07t4e8/ujRoygoKAAwPJ6Dn/Lss88iKysLN910U8w25NbAQO941Vi/fr3xeDxm3bp15tChQ+aee+4xaWlppr6+fqCb1i+0traaffv2mX379hkA5oknnjD79u0zn3zyiTHGmMcee8ykpaWZ3/3ud+bAgQNm0aJFpqioyHR2dg5wy/uGpUuXmtTUVLN9+3ZTV1cXOzo6OmLX3HvvvSY/P99s27bN7N2715SUlJiSkpIBbHXf8dBDD5mKigpTVVVlDhw4YB566CFjs9nMm2++aYwZ2n3X+O9qF2OG/hh8+9vfNtu3bzdVVVXmnXfeMaWlpWbUqFGmsbHRGDP0+//ee+8Zp9NpfvSjH5ljx46Zf//3fzdJSUnm17/+deyaof4cNOaCsjM/P988+OCDPc4NpTUwaIMPY4z5l3/5F5Ofn2/cbreZPXu22bVr10A3qd946623DIAex5IlS4wxF2Rm3/ve94zX6zUej8fMnz/fHDlyZGAb3YdIfQdgnn322dg1nZ2d5pvf/KZJT083SUlJ5uabbzZ1dXUD1+g+5O677zYFBQXG7Xab0aNHm/nz58cCD2OGdt81Lg4+hvoY3HbbbSY7O9u43W6Tm5trbrvtNnP8+PHY+aHef2OMee2118zUqVONx+MxkyZNMr/85S+7nR/qz0FjjNm0aZMBIPZrKK0BmzHGDMhXLoQQQggZlgzKPR+EEEIIGbow+CCEEEJIXGHwQQghhJC4wuCDEEIIIXGFwQchhBBC4gqDD0IIIYTEFQYfhBBCCIkrDD4IIYQQElcYfBBCCCEkrjD4IIQQQkhcYfBBCCGEkLjy/wHOclOSCapGzAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(distances2.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[np.int64(0)] [0]\n",
      "[np.int64(76)] [76]\n",
      "[np.int64(76)] [76]\n",
      "[np.int64(23)] [23]\n",
      "[np.int64(6)] [6]\n",
      "[np.int64(24)] [24]\n",
      "[np.int64(48)] [48]\n",
      "[np.int64(23)] [23]\n",
      "[np.int64(76)] [76]\n",
      "[np.int64(76)] [76]\n",
      "[np.int64(76)] [76]\n",
      "[np.int64(76)] [76]\n",
      "[np.int64(23)] [23]\n",
      "[np.int64(76)] [76]\n",
      "[np.int64(1)] [1]\n",
      "[np.int64(29)] [29]\n",
      "[np.int64(23)] [23]\n",
      "[np.int64(76)] [76]\n"
     ]
    }
   ],
   "source": [
    "[print(x,y) for x,y in zip(matching1, matching2)];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conformalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-08-20 19:38:40:WARNING:cp.py:cp:748 - __init__ ] No multiple_testing_correction provided, assuming no correction is needed. The explicit list of alphas is expected for calibration.\n",
      "[2025-08-20 19:38:40:INFO:cp.py:cp:184 - __init__ ] Defaulting to CRC backend\n",
      "[2025-08-20 19:38:40:INFO:cp.py:cp:512 - __init__ ] Defaulting to CRC backend\n"
     ]
    }
   ],
   "source": [
    "from cods.od.cp import ODConformalizer\n",
    "\n",
    "conf = ODConformalizer(\n",
    "    backend=\"auto\",\n",
    "    guarantee_level=\"image\",\n",
    "    matching_function=\"mix\",\n",
    "    multiple_testing_correction=None,\n",
    "    confidence_method=\"box_count_recall\",\n",
    "    localization_method=\"pixelwise\",\n",
    "    localization_prediction_set=\"multiplicative\",\n",
    "    classification_method=\"binary\",\n",
    "    classification_prediction_set=\"lac\",\n",
    "    device=\"cuda:0\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-08-20 19:38:40:INFO:models.py:models:30 - __init__ ] Model detr_resnet50 initialized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/leo.andeol/.cache/torch/hub/facebookresearch_detr_main\n",
      "/home/leo.andeol/envs/cods_13/cods/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/leo.andeol/envs/cods_13/cods/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = DETRModel(model_name=\"detr_resnet50\", pretrained=True, device=\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leo.andeol/envs/cods_13/cods/cods/od/utils.py:493: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
      "  Qst = torch.FloatTensor([np.array(Qs)]).to(device)\n",
      "[2025-08-20 19:38:42:INFO:optim.py:optim:195 - optimize ] First risk: 0.0037406485062092543\n",
      "[2025-08-20 19:38:42:WARNING:optim.py:optim:202 - optimize ] There does not exist any solution satisfying the constraints.\n",
      "[2025-08-20 19:38:43:INFO:optim.py:optim:195 - optimize ] First risk: 0.0012468828354030848\n",
      "[2025-08-20 19:38:43:WARNING:optim.py:optim:202 - optimize ] There does not exist any solution satisfying the constraints.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.0, 1.0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf.confidence_conformalizer.calibrate(preds_cal, 0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-08-20 19:38:43:INFO:cp.py:cp:988 - calibrate ] Calibrating Confidence Conformalizer\n",
      "[2025-08-20 19:38:43:INFO:cp.py:cp:398 - calibrate ] Replacing previously computed λ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-08-20 19:38:44:INFO:optim.py:optim:195 - optimize ] First risk: 0.0037406485062092543\n",
      "[2025-08-20 19:39:12:INFO:optim.py:optim:418 - optimize ] Solution Found: 0.9259868562221527 with risk 0.02025293931365013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Lambdas\n",
      "\tprevious_lbd = 0.9259868562221527\n",
      "\tLast Lambda = 0.9258964955806732\n",
      "\tOther previous lbd = 0.9259868562221527\n",
      "\tOther current lbd = 0.9258964955806732\n",
      "All risks raw (precomputed):\n",
      "\tConfidence Risk: 0.019421685487031937\n",
      "\tLocalization Risk: 0.0024937656708061695\n",
      "\tClassification Risk: 0.0024937656708061695\n",
      "\tMax Risk: 0.019421685487031937\n",
      "All risks monotonized (precomputed):\n",
      "\tConfidence Risk: 0.019421685487031937\n",
      "\tLocalization Risk: 0.0024937656708061695\n",
      "\tClassification Risk: 0.0024937656708061695\n",
      "\tMax Risk: 0.019421685487031937\n",
      "Confidence risk (recomputed):\n",
      "\tConfidence Risk: 0.016970237717032433\n",
      "Comparison of the two :\n",
      "\t (isclose) 0.9975000023841858\n",
      "\t (eq) 0.9975000023841858\n",
      "\tImage 241 loss: tensor([0.], device='cuda:0') (eval) vs tensor([0.3333], device='cuda:0') (opti)\n",
      "\tImage 241 confidence: tensor([0.9993, 0.9794, 0.0740, 0.0028], device='cuda:0')\n",
      "\tImage 241 number of ground truths: 3\n",
      "\tImage 241 number of predictions: 3\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-08-20 19:39:13:INFO:optim.py:optim:195 - optimize ] First risk: 0.0012468828354030848\n",
      "[2025-08-20 19:39:44:INFO:optim.py:optim:418 - optimize ] Solution Found: 0.8939756602048874 with risk 0.02033606544137001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Lambdas\n",
      "\tprevious_lbd = 0.8939756602048874\n",
      "\tLast Lambda = 0.893954761326313\n",
      "\tOther previous lbd = 0.8939756602048874\n",
      "\tOther current lbd = 0.893954761326313\n",
      "All risks raw (precomputed):\n",
      "\tConfidence Risk: 0.019837312400341034\n",
      "\tLocalization Risk: 0.0\n",
      "\tClassification Risk: 0.0\n",
      "\tMax Risk: 0.019837312400341034\n",
      "All risks monotonized (precomputed):\n",
      "\tConfidence Risk: 0.019837312400341034\n",
      "\tLocalization Risk: 0.0\n",
      "\tClassification Risk: 0.0\n",
      "\tMax Risk: 0.019837312400341034\n",
      "Confidence risk (recomputed):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-08-20 19:39:44:INFO:cp.py:cp:998 - calibrate ] Setting Confidence Threshold of Predictions\n",
      "[2025-08-20 19:39:44:INFO:cp.py:cp:1010 - calibrate ] Calibrated Confidence λ : 0.9260\n",
      "\t and associated Confidence Threshold : 0.07401314377784729\n",
      "[2025-08-20 19:39:44:INFO:cp.py:cp:1025 - calibrate ] Matching Predictions to True Boxes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tConfidence Risk: 0.019886905327439308\n",
      "Comparison of the two :\n",
      "\t (isclose) 0.9975000023841858\n",
      "\t (eq) 0.9975000023841858\n",
      "\tImage 321 loss: tensor([0.4000], device='cuda:0') (eval) vs tensor([0.6000], device='cuda:0') (opti)\n",
      "\tImage 321 confidence: tensor([0.9971, 0.9690, 0.1060, 0.0123, 0.0094, 0.0072, 0.0055, 0.0019, 0.0017, 0.0016, 0.0015, 0.0015, 0.0012], device='cuda:0')\n",
      "\tImage 321 number of ground truths: 5\n",
      "\tImage 321 number of predictions: 3\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "400it [00:00, 5558.44it/s]\n",
      "[2025-08-20 19:39:44:INFO:cp.py:cp:1038 - calibrate ] Calibrating Localization Conformalizer\n",
      "[2025-08-20 19:39:44:INFO:optim.py:optim:754 - optimize ] Using overload confidence threshold: 0.1060\n",
      "[0.29, 0.32] -> λ=0.30517578125. Corrected Risk = 0.051: 100%|██████████| 13/13 [03:24<00:00, 15.75s/it]\n",
      "[2025-08-20 19:43:09:INFO:cp.py:cp:268 - calibrate ] Calibrated λ for localization: 0.3173828125\n",
      "[2025-08-20 19:43:09:INFO:cp.py:cp:1048 - calibrate ] Calibrated Localization λ : 0.3173828125\n",
      "[2025-08-20 19:43:09:INFO:cp.py:cp:1056 - calibrate ] Calibrating Classification Conformalizer\n",
      "[2025-08-20 19:43:09:WARNING:cp.py:cp:542 - calibrate ] Currently considering that there is only one matching prediction to each true box for classification pruposes. To add later how to aggregate if multiple preidctions matched.\n",
      "[2025-08-20 19:43:09:INFO:optim.py:optim:754 - optimize ] Using overload confidence threshold: 0.1060\n",
      "[1.00, 1.00] -> λ=0.9999978244304657. Corrected Risk = 0.051: 100%|██████████| 25/25 [08:07<00:00, 19.49s/it]\n",
      "[2025-08-20 19:51:16:INFO:cp.py:cp:594 - calibrate ] Calibrated λ for classification: 0.9999978542327881\n",
      "[2025-08-20 19:51:16:INFO:cp.py:cp:1066 - calibrate ] Calibrated Classification λ : 0.9999978542327881\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-09 s\n",
      "\n",
      "Total time: 60.7362 s\n",
      "File: /home/leo.andeol/envs/cods_13/cods/cods/od/optim.py\n",
      "Function: optimize at line 42\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "    42                                               def optimize(\n",
      "    43                                                   self,\n",
      "    44                                                   predictions: ODPredictions,\n",
      "    45                                                   confidence_loss: ODLoss,\n",
      "    46                                                   localization_loss: ODLoss,\n",
      "    47                                                   classification_loss: ODLoss,\n",
      "    48                                                   matching_function,\n",
      "    49                                                   alpha: float,\n",
      "    50                                                   device: str,\n",
      "    51                                                   B: float = 1,\n",
      "    52                                                   init_lambda: float = 1,\n",
      "    53                                                   verbose: bool = False,\n",
      "    54                                               ):\n",
      "    55         2       1041.0    520.5      0.0          true_boxes = predictions.true_boxes\n",
      "    56         2        811.0    405.5      0.0          pred_boxes = predictions.pred_boxes\n",
      "    57         2       1062.0    531.0      0.0          true_cls = predictions.true_cls\n",
      "    58         2        490.0    245.0      0.0          pred_cls = predictions.pred_cls\n",
      "    59         2       1072.0    536.0      0.0          image_shapes = predictions.image_shapes\n",
      "    60         2        571.0    285.5      0.0          confidences = predictions.confidences\n",
      "    61                                           \n",
      "    62         4     608338.0 152084.5      0.0          stacked_confidences = torch.concatenate(\n",
      "    63         2        180.0     90.0      0.0              confidences,\n",
      "    64                                                   )\n",
      "    65         4     471319.0 117829.8      0.0          confidence_image_idx = torch.concatenate(\n",
      "    66         2    8023005.0    4e+06      0.0              [torch.ones_like(x, dtype=int) * i for i, x in enumerate(confidences)],\n",
      "    67                                                   )\n",
      "    68                                           \n",
      "    69         2     135206.0  67603.0      0.0          sorted_stacked_confidences, indices = torch.sort(stacked_confidences)\n",
      "    70         2      68179.0  34089.5      0.0          sorted_stacked_confidences[:-1] = sorted_stacked_confidences[1:].clone()\n",
      "    71         2      34595.0  17297.5      0.0          sorted_stacked_confidences[-1] = 1.0  # last one is always 1.0\n",
      "    72         2      35787.0  17893.5      0.0          sorted_confidence_image_indices = confidence_image_idx[indices]\n",
      "    73                                           \n",
      "    74         2        360.0    180.0      0.0          lambda_conf = init_lambda\n",
      "    75                                           \n",
      "    76         2        391.0    195.5      0.0          confidence_losses = []\n",
      "    77         2        362.0    181.0      0.0          localization_losses = []\n",
      "    78         2        370.0    185.0      0.0          classification_losses = []\n",
      "    79                                           \n",
      "    80                                                   # Step 0: Initialize the risk\n",
      "    81                                           \n",
      "    82         4  204474517.0    5e+07      0.3          match_predictions_to_true_boxes(\n",
      "    83         2        380.0    190.0      0.0              predictions,\n",
      "    84         2        320.0    160.0      0.0              distance_function=matching_function,\n",
      "    85         2        180.0     90.0      0.0              verbose=False,\n",
      "    86         2        512.0    256.0      0.0              overload_confidence_threshold=1 - lambda_conf,\n",
      "    87                                                   )\n",
      "    88                                           \n",
      "    89                                                   # TODO(leo):parallelize?\n",
      "    90                                                   # Step 1: Compute the risk\n",
      "    91       802     739582.0    922.2      0.0          for i in tqdm(range(len(predictions)), disable=not verbose):\n",
      "    92       800     216045.0    270.1      0.0              true_boxes_i = true_boxes[i]\n",
      "    93       800     632832.0    791.0      0.0              pred_boxes_i = pred_boxes[i]\n",
      "    94       800     164380.0    205.5      0.0              confidences_i = confidences[i]\n",
      "    95       800     164873.0    206.1      0.0              true_cls_i = true_cls[i]\n",
      "    96       800     594660.0    743.3      0.0              pred_cls_i = pred_cls[i]\n",
      "    97       800     189401.0    236.8      0.0              image_shape = image_shapes[i]\n",
      "    98                                           \n",
      "    99       800     344781.0    431.0      0.0              matching_i = predictions.matching[i]\n",
      "   100                                           \n",
      "   101       800   40977396.0  51221.7      0.1              pred_boxes_i = pred_boxes_i[confidences_i >= 1 - lambda_conf]\n",
      "   102       800  380990423.0 476238.0      0.6              pred_cls_i = [x for x, c in zip(pred_cls_i, confidences_i) if c >= 1 - lambda_conf]\n",
      "   103       800    3343986.0   4180.0      0.0              pred_cls_i = (\n",
      "   104       800   15848762.0  19811.0      0.0                  torch.stack(pred_cls_i)\n",
      "   105       800     548460.0    685.6      0.0                  if len(pred_cls_i) > 0\n",
      "   106                                                           else torch.tensor([]).float().to(device)\n",
      "   107                                                       )\n",
      "   108                                           \n",
      "   109                                                       # no confidence filtering here because lambda_conf = 1 for this first loop\n",
      "   110      1600   39486730.0  24679.2      0.1              confidence_loss_i = confidence_loss(\n",
      "   111       800     122003.0    152.5      0.0                  true_boxes_i,\n",
      "   112       800     101478.0    126.8      0.0                  true_cls_i,\n",
      "   113       800     113104.0    141.4      0.0                  pred_boxes_i,\n",
      "   114       800      63575.0     79.5      0.0                  pred_cls_i,\n",
      "   115                                                       )\n",
      "   116                                           \n",
      "   117      1600   88495567.0  55309.7      0.1              tmp_matched_boxes_i = [\n",
      "   118                                                           (\n",
      "   119                                                               torch.stack([pred_boxes_i[m] for m in matching_i[j]])[0]\n",
      "   120                                                               if len(matching_i[j]) > 0\n",
      "   121                                                               else torch.tensor([]).float().to(device)\n",
      "   122                                                           )\n",
      "   123       800    1830785.0   2288.5      0.0                  for j in range(len(true_boxes_i))\n",
      "   124                                                       ]\n",
      "   125       800     568548.0    710.7      0.0              matched_pred_boxes_i = (\n",
      "   126       792    8198966.0  10352.2      0.0                  torch.stack(tmp_matched_boxes_i)\n",
      "   127       800     309308.0    386.6      0.0                  if len(tmp_matched_boxes_i) > 0\n",
      "   128         8     102282.0  12785.2      0.0                  else torch.tensor([]).float().to(device)\n",
      "   129                                                       )\n",
      "   130      1600   77427962.0  48392.5      0.1              matched_pred_cls_i = [\n",
      "   131                                                           (\n",
      "   132                                                               torch.stack([pred_cls_i[m] for m in matching_i[j]])[0]  # TODO zero here ?\n",
      "   133                                                               if len(matching_i[j]) > 0\n",
      "   134                                                               else torch.tensor([]).float().to(device)\n",
      "   135                                                           )\n",
      "   136       800    2426314.0   3032.9      0.0                  for j in range(len(true_boxes_i))\n",
      "   137                                                       ]\n",
      "   138       800    5087363.0   6359.2      0.0              margin = np.concatenate((image_shape, image_shape))\n",
      "   139      2400   53664624.0  22360.3      0.1              matched_conf_boxes_i = apply_margins(\n",
      "   140       800     195980.0    245.0      0.0                  [matched_pred_boxes_i],\n",
      "   141       800      89555.0    111.9      0.0                  margin,\n",
      "   142       800      81983.0    102.5      0.0                  mode=\"additive\",  # TODO fix this\n",
      "   143       800     124194.0    155.2      0.0              )[0]\n",
      "   144                                           \n",
      "   145       800    8555037.0  10693.8      0.0              n_classes = len(predictions.pred_cls[0][0].squeeze())\n",
      "   146      1600   91738747.0  57336.7      0.2              matched_conf_cls_i = [\n",
      "   147                                                           torch.arange(n_classes)[None, ...].to(device)\n",
      "   148       800     364071.0    455.1      0.0                  for _ in range(len(matched_pred_cls_i))\n",
      "   149                                                       ]\n",
      "   150                                           \n",
      "   151      1600  155904329.0  97440.2      0.3              localization_loss_i = localization_loss(\n",
      "   152       800      98989.0    123.7      0.0                  true_boxes_i,\n",
      "   153       800      74925.0     93.7      0.0                  true_cls_i,\n",
      "   154       800      70515.0     88.1      0.0                  matched_conf_boxes_i,\n",
      "   155       800      61078.0     76.3      0.0                  matched_conf_cls_i,\n",
      "   156                                                       )\n",
      "   157      1600 1040991464.0 650619.7      1.7              classification_loss_i = classification_loss(\n",
      "   158       800      91788.0    114.7      0.0                  true_boxes_i,\n",
      "   159       800      80077.0    100.1      0.0                  true_cls_i,\n",
      "   160       800      78697.0     98.4      0.0                  matched_conf_boxes_i,\n",
      "   161       800      59661.0     74.6      0.0                  matched_conf_cls_i,\n",
      "   162                                                       )\n",
      "   163                                           \n",
      "   164       800     466759.0    583.4      0.0              confidence_losses.append(confidence_loss_i)\n",
      "   165       800     189482.0    236.9      0.0              localization_losses.append(localization_loss_i)\n",
      "   166       800     272501.0    340.6      0.0              classification_losses.append(classification_loss_i)\n",
      "   167                                           \n",
      "   168                                                   # TODO(leo): image level\n",
      "   169         4     287393.0  71848.2      0.0          confidence_risk = self._correct_risk(\n",
      "   170         2        220.0    110.0      0.0              confidence_losses,\n",
      "   171         2       4248.0   2124.0      0.0              len(predictions),\n",
      "   172         2        160.0     80.0      0.0              B,\n",
      "   173                                                   )\n",
      "   174         4     249291.0  62322.8      0.0          localization_risk = self._correct_risk(\n",
      "   175         2        220.0    110.0      0.0              localization_losses,\n",
      "   176         2       2245.0   1122.5      0.0              len(predictions),\n",
      "   177         2        190.0     95.0      0.0              B,\n",
      "   178                                                   )\n",
      "   179         4     261854.0  65463.5      0.0          classification_risk = self._correct_risk(\n",
      "   180         2        271.0    135.5      0.0              classification_losses,\n",
      "   181         2       2044.0   1022.0      0.0              len(predictions),\n",
      "   182         2        170.0     85.0      0.0              B,\n",
      "   183                                                   )\n",
      "   184                                           \n",
      "   185                                                   # ------- LOGGING -------\n",
      "   186         2       3236.0   1618.0      0.0          _log_raw_confidence_losses = confidence_losses.copy()\n",
      "   187         2       1573.0    786.5      0.0          _log_raw_localization_losses = localization_losses.copy()\n",
      "   188         2       1333.0    666.5      0.0          _log_raw_classification_losses = classification_losses.copy()\n",
      "   189                                           \n",
      "   190         4      27382.0   6845.5      0.0          max_risk = torch.max(\n",
      "   191         4      21299.0   5324.8      0.0              torch.stack(\n",
      "   192         2        520.0    260.0      0.0                  [confidence_risk, localization_risk, classification_risk],\n",
      "   193                                                       ),\n",
      "   194                                                   )\n",
      "   195         2     980883.0 490441.5      0.0          logger.info(f\"First risk: {max_risk.detach().cpu().numpy()}\")\n",
      "   196         2      86824.0  43412.0      0.0          if max_risk.detach().cpu().numpy() > alpha:\n",
      "   197                                                       # Debug: all three risks to see why there isn't any solution\n",
      "   198                                                       logger.debug(f\"Confidence risk: {confidence_risk}\")\n",
      "   199                                                       logger.debug(f\"Localization risk: {localization_risk}\")\n",
      "   200                                                       logger.debug(f\"Classification risk: {classification_risk}\")\n",
      "   201                                                       logger.debug(f\"Max risk: {max_risk} > {alpha}. No solution found.\")\n",
      "   202                                                       logger.warning(\n",
      "   203                                                           \"There does not exist any solution satisfying the constraints.\",\n",
      "   204                                                       )\n",
      "   205                                                       return 1.0\n",
      "   206         4       4949.0   1237.2      0.0          logger.debug(\n",
      "   207         2     196951.0  98475.5      0.0              f\"Risk after 1st epoch is {max_risk.detach().cpu().numpy()} < {alpha}\",\n",
      "   208                                                   )\n",
      "   209                                           \n",
      "   210         2        331.0    165.5      0.0          previous_lbd = lambda_conf\n",
      "   211         2        271.0    135.5      0.0          previous_risk = max_risk\n",
      "   212                                           \n",
      "   213         4     162997.0  40749.2      0.0          pbar = tqdm(\n",
      "   214         4    2779197.0 694799.2      0.0              list(\n",
      "   215         4  284022968.0    7e+07      0.5                  zip(\n",
      "   216         2        230.0    115.0      0.0                      sorted_confidence_image_indices,\n",
      "   217         2        160.0     80.0      0.0                      sorted_stacked_confidences,\n",
      "   218                                                           ),\n",
      "   219                                                       ),\n",
      "   220         2        752.0    376.0      0.0              disable=not verbose,\n",
      "   221                                                   )\n",
      "   222                                           \n",
      "   223         2     179659.0  89829.5      0.0          self.all_risks_raw = [max_risk.detach().cpu().numpy()]\n",
      "   224         2      30788.0  15394.0      0.0          self.all_risks_raw_conf = [confidence_risk.detach().cpu().numpy()]\n",
      "   225         2      23464.0  11732.0      0.0          self.all_risks_raw_loc = [localization_risk.detach().cpu().numpy()]\n",
      "   226         2      24457.0  12228.5      0.0          self.all_risks_raw_cls = [classification_risk.detach().cpu().numpy()]\n",
      "   227         2      22563.0  11281.5      0.0          self.all_risks_mon = [max_risk.detach().cpu().numpy()]\n",
      "   228         2      21361.0  10680.5      0.0          self.all_risks_mon_conf = [confidence_risk.detach().cpu().numpy()]\n",
      "   229         2      21130.0  10565.0      0.0          self.all_risks_mon_loc = [localization_risk.detach().cpu().numpy()]\n",
      "   230         2      20299.0  10149.5      0.0          self.all_risks_mon_cls = [classification_risk.detach().cpu().numpy()]\n",
      "   231         2        812.0    406.0      0.0          self.all_lbds = [lambda_conf]\n",
      "   232                                           \n",
      "   233                                                   # Step 2: Update one loss at a time\n",
      "   234     13071   14327930.0   1096.2      0.0          for image_id, conf_score in pbar:\n",
      "   235     13071    2264896.0    173.3      0.0              previous_lbd = lambda_conf\n",
      "   236     13071   12493182.0    955.8      0.0              previous_risk = max_risk\n",
      "   237     13071  171254801.0  13101.9      0.3              lambda_conf = 1 - conf_score.cpu().numpy().item()\n",
      "   238     13071    4890298.0    374.1      0.0              if lambda_conf > init_lambda:\n",
      "   239                                                           continue\n",
      "   240                                           \n",
      "   241     13071    2203336.0    168.6      0.0              i = image_id\n",
      "   242     13071  136242267.0  10423.2      0.2              true_boxes_i = true_boxes[i]\n",
      "   243     13071   95571737.0   7311.7      0.2              pred_boxes_i = pred_boxes[i]\n",
      "   244     13071   83625529.0   6397.8      0.1              confidences_i = confidences[i]\n",
      "   245     13071   81858585.0   6262.6      0.1              true_cls_i = true_cls[i]\n",
      "   246     13071   91315963.0   6986.1      0.2              pred_cls_i = pred_cls[i]\n",
      "   247     13071   82864415.0   6339.6      0.1              image_shape = image_shapes[i]\n",
      "   248                                           \n",
      "   249     13071  731149993.0  55936.8      1.2              pred_boxes_i = pred_boxes_i[confidences_i >= 1 - lambda_conf]\n",
      "   250     13071 8378883553.0 641028.5     13.8              pred_cls_i = [x for x, c in zip(pred_cls_i, confidences_i) if c >= 1 - lambda_conf]\n",
      "   251     13071   53889846.0   4122.9      0.1              pred_cls_i = (\n",
      "   252     13065  258676380.0  19799.2      0.4                  torch.stack(pred_cls_i)\n",
      "   253     13071    8919914.0    682.4      0.0                  if len(pred_cls_i) > 0\n",
      "   254         6     129393.0  21565.5      0.0                  else torch.tensor([]).float().to(device)\n",
      "   255                                                       )\n",
      "   256                                           \n",
      "   257     26142  684022049.0  26165.6      1.1              confidence_loss_i = confidence_loss(\n",
      "   258     13071    1510158.0    115.5      0.0                  true_boxes_i,\n",
      "   259     13071    1174705.0     89.9      0.0                  true_cls_i,\n",
      "   260     13071    1590081.0    121.6      0.0                  pred_boxes_i,\n",
      "   261     13071    1015803.0     77.7      0.0                  pred_cls_i,\n",
      "   262                                                       )\n",
      "   263                                           \n",
      "   264     26142 5453985953.0 208629.3      9.0              matching_i = match_predictions_to_true_boxes(\n",
      "   265     13071    1372833.0    105.0      0.0                  predictions,\n",
      "   266     13071    1308453.0    100.1      0.0                  distance_function=matching_function,\n",
      "   267     13071    1372437.0    105.0      0.0                  verbose=False,\n",
      "   268     13071    4774826.0    365.3      0.0                  overload_confidence_threshold=1 - lambda_conf,\n",
      "   269     13071    1280200.0     97.9      0.0                  idx=i,\n",
      "   270                                                       )\n",
      "   271                                           \n",
      "   272     13071  144533262.0  11057.6      0.2              predictions.matching[i] = matching_i\n",
      "   273                                           \n",
      "   274     26142 1585456623.0  60647.9      2.6              tmp_matched_boxes_i = [\n",
      "   275                                                           (\n",
      "   276                                                               torch.stack([pred_boxes_i[m] for m in matching_i[j]])[0]\n",
      "   277                                                               if len(matching_i[j]) > 0\n",
      "   278                                                               else torch.tensor([]).float().to(device)\n",
      "   279                                                           )\n",
      "   280     13071   53248206.0   4073.8      0.1                  for j in range(len(true_boxes_i))\n",
      "   281                                                       ]\n",
      "   282     13071    9574426.0    732.5      0.0              matched_pred_boxes_i = (\n",
      "   283     13029  143364359.0  11003.5      0.2                  torch.stack(tmp_matched_boxes_i)\n",
      "   284     13071    4697271.0    359.4      0.0                  if len(tmp_matched_boxes_i) > 0\n",
      "   285        42     744812.0  17733.6      0.0                  else torch.tensor([]).float().to(device)\n",
      "   286                                                       )\n",
      "   287     26142 1382537434.0  52885.7      2.3              matched_pred_cls_i = [\n",
      "   288                                                           (\n",
      "   289                                                               torch.stack([pred_cls_i[m] for m in matching_i[j]])[0]\n",
      "   290                                                               if len(matching_i[j]) > 0\n",
      "   291                                                               else torch.tensor([]).float().to(device)\n",
      "   292                                                           )\n",
      "   293     13071   42213186.0   3229.5      0.1                  for j in range(len(true_boxes_i))\n",
      "   294                                                       ]\n",
      "   295                                           \n",
      "   296     13071   86941555.0   6651.5      0.1              margin = np.concatenate((image_shape, image_shape))\n",
      "   297     39213  925439951.0  23600.3      1.5              matched_conf_boxes_i = apply_margins(\n",
      "   298     13071    2668246.0    204.1      0.0                  [matched_pred_boxes_i],\n",
      "   299     13071    1432408.0    109.6      0.0                  margin,\n",
      "   300     13071    1406039.0    107.6      0.0                  mode=\"additive\",  # TODO: fix this\n",
      "   301     13071    2128151.0    162.8      0.0              )[0]\n",
      "   302                                           \n",
      "   303     13071  145536314.0  11134.3      0.2              n_classes = len(predictions.pred_cls[0][0].squeeze())\n",
      "   304     26142 1637973648.0  62656.8      2.7              matched_conf_cls_i = [\n",
      "   305                                                           torch.arange(n_classes)[None, ...].to(device)\n",
      "   306     13071    6219340.0    475.8      0.0                  for _ in range(len(matched_pred_cls_i))\n",
      "   307                                                       ]\n",
      "   308                                           \n",
      "   309     26142 2646346822.0 101229.7      4.4              localization_loss_i = localization_loss(\n",
      "   310     13071    1558647.0    119.2      0.0                  true_boxes_i,\n",
      "   311     13071    1322616.0    101.2      0.0                  true_cls_i,\n",
      "   312     13071    1523763.0    116.6      0.0                  matched_conf_boxes_i,\n",
      "   313     13071    1031328.0     78.9      0.0                  matched_conf_cls_i,\n",
      "   314                                                       )\n",
      "   315     26142        2e+10 698661.1     30.1              classification_loss_i = classification_loss(\n",
      "   316     13071    1800802.0    137.8      0.0                  true_boxes_i,\n",
      "   317     13071    1540481.0    117.9      0.0                  true_cls_i,\n",
      "   318     13071    1586731.0    121.4      0.0                  matched_conf_boxes_i,\n",
      "   319     13071    1034372.0     79.1      0.0                  matched_conf_cls_i,\n",
      "   320                                                       )\n",
      "   321                                           \n",
      "   322     13071  305139742.0  23344.8      0.5              _log_raw_confidence_losses[i] = confidence_loss_i.detach().clone()\n",
      "   323     13071  207031376.0  15839.0      0.3              _log_raw_localization_losses[i] = localization_loss_i.detach().clone()\n",
      "   324     13071  192274104.0  14710.0      0.3              _log_raw_classification_losses[i] = classification_loss_i.detach().clone()\n",
      "   325                                           \n",
      "   326     26142  325456791.0  12449.6      0.5              confidence_losses[i] = max(\n",
      "   327     13071   91481402.0   6998.8      0.2                  confidence_loss_i.detach().clone(),\n",
      "   328     13071  166326286.0  12724.8      0.3                  confidence_losses[i].clone(),\n",
      "   329                                                       )\n",
      "   330     26142  283838228.0  10857.6      0.5              localization_losses[i] = max(\n",
      "   331     13071  115379598.0   8827.1      0.2                  localization_loss_i.detach().clone(),\n",
      "   332     13071  165990802.0  12699.2      0.3                  localization_losses[i].clone(),\n",
      "   333                                                       )\n",
      "   334     26142  282330178.0  10799.9      0.5              classification_losses[i] = max(\n",
      "   335     13071  112709574.0   8622.9      0.2                  classification_loss_i.detach().clone(),\n",
      "   336     13071  164918816.0  12617.2      0.3                  classification_losses[i].clone(),\n",
      "   337                                                       )\n",
      "   338                                           \n",
      "   339     26142 1760944960.0  67360.8      2.9              confidence_risk = self._correct_risk(\n",
      "   340     13071    1801488.0    137.8      0.0                  confidence_losses,\n",
      "   341     13071   22623543.0   1730.8      0.0                  len(predictions),\n",
      "   342     13071    1361429.0    104.2      0.0                  B,\n",
      "   343                                                       )\n",
      "   344     26142 1568682022.0  60006.2      2.6              localization_risk = self._correct_risk(\n",
      "   345     13071    1427405.0    109.2      0.0                  localization_losses,\n",
      "   346     13071   15650538.0   1197.3      0.0                  len(predictions),\n",
      "   347     13071    1176981.0     90.0      0.0                  B,\n",
      "   348                                                       )\n",
      "   349     26142 1534011016.0  58679.9      2.5              classification_risk = self._correct_risk(\n",
      "   350     13071    2018661.0    154.4      0.0                  classification_losses,\n",
      "   351     13071   14158665.0   1083.2      0.0                  len(predictions),\n",
      "   352     13071    1132071.0     86.6      0.0                  B,\n",
      "   353                                                       )\n",
      "   354                                           \n",
      "   355     26142  126535216.0   4840.3      0.2              max_risk = torch.max(\n",
      "   356     26142  129525147.0   4954.7      0.2                  torch.stack(\n",
      "   357     13071    3436385.0    262.9      0.0                      [confidence_risk, localization_risk, classification_risk],\n",
      "   358                                                           ),\n",
      "   359                                                       )\n",
      "   360     26142 1548232487.0  59223.9      2.5              _log_raw_confidence_risk = self._correct_risk(\n",
      "   361     13071    2080072.0    159.1      0.0                  _log_raw_confidence_losses,\n",
      "   362     13071   15441714.0   1181.4      0.0                  len(predictions),\n",
      "   363     13071    1162959.0     89.0      0.0                  B,\n",
      "   364                                                       )\n",
      "   365     26142 1537665887.0  58819.7      2.5              _log_raw_localization_risk = self._correct_risk(\n",
      "   366     13071    1797780.0    137.5      0.0                  _log_raw_localization_losses,\n",
      "   367     13071   12587218.0    963.0      0.0                  len(predictions),\n",
      "   368     13071    1158069.0     88.6      0.0                  B,\n",
      "   369                                                       )\n",
      "   370     26142 1520203096.0  58151.8      2.5              _log_raw_classification_risk = self._correct_risk(\n",
      "   371     13071    1752462.0    134.1      0.0                  _log_raw_classification_losses,\n",
      "   372     13071   11940327.0    913.5      0.0                  len(predictions),\n",
      "   373     13071    1108168.0     84.8      0.0                  B,\n",
      "   374                                                       )\n",
      "   375     26142  118002118.0   4513.9      0.2              _log_raw_max_risk = torch.max(\n",
      "   376     26142  122713098.0   4694.1      0.2                  torch.stack(\n",
      "   377     13071    2456521.0    187.9      0.0                      [\n",
      "   378     13071    1302639.0     99.7      0.0                          _log_raw_confidence_risk,\n",
      "   379     13071    1346640.0    103.0      0.0                          _log_raw_localization_risk,\n",
      "   380     13071    1151842.0     88.1      0.0                          _log_raw_classification_risk,\n",
      "   381                                                               ],\n",
      "   382                                                           ),\n",
      "   383                                                       )\n",
      "   384     13071    9049052.0    692.3      0.0              self.all_lbds.append(lambda_conf)\n",
      "   385     13071  285231406.0  21821.7      0.5              self.all_risks_raw.append(_log_raw_max_risk.detach().cpu().numpy())\n",
      "   386     26142    6701561.0    256.4      0.0              self.all_risks_raw_conf.append(\n",
      "   387     13071  148020509.0  11324.3      0.2                  _log_raw_confidence_risk.detach().cpu().numpy(),\n",
      "   388                                                       )\n",
      "   389     26142    5001598.0    191.3      0.0              self.all_risks_raw_loc.append(\n",
      "   390     13071  132689381.0  10151.4      0.2                  _log_raw_localization_risk.detach().cpu().numpy(),\n",
      "   391                                                       )\n",
      "   392     26142    5741745.0    219.6      0.0              self.all_risks_raw_cls.append(\n",
      "   393     13071  129220761.0   9886.1      0.2                  _log_raw_classification_risk.detach().cpu().numpy(),\n",
      "   394                                                       )\n",
      "   395                                           \n",
      "   396     13071  139282110.0  10655.8      0.2              self.all_risks_mon.append(max_risk.detach().cpu().numpy())\n",
      "   397     26142    6460708.0    247.1      0.0              self.all_risks_mon_conf.append(\n",
      "   398     13071  136731884.0  10460.7      0.2                  confidence_risk.detach().cpu().numpy()\n",
      "   399     13071    8704534.0    665.9      0.0                  if isinstance(confidence_risk, torch.Tensor)\n",
      "   400                                                           else confidence_risk,\n",
      "   401                                                       )\n",
      "   402     26142    4819339.0    184.4      0.0              self.all_risks_mon_loc.append(\n",
      "   403     13071  132700379.0  10152.3      0.2                  localization_risk.detach().cpu().numpy()\n",
      "   404     13071    3773521.0    288.7      0.0                  if isinstance(localization_risk, torch.Tensor)\n",
      "   405                                                           else localization_risk,\n",
      "   406                                                       )\n",
      "   407     26142    4855867.0    185.7      0.0              self.all_risks_mon_cls.append(\n",
      "   408     13071  131069844.0  10027.5      0.2                  classification_risk.detach().cpu().numpy()\n",
      "   409     13071    3463954.0    265.0      0.0                  if isinstance(classification_risk, torch.Tensor)\n",
      "   410                                                           else classification_risk,\n",
      "   411                                                       )\n",
      "   412                                           \n",
      "   413     26142   30047388.0   1149.4      0.0              pbar.set_description(\n",
      "   414     13071  202107850.0  15462.3      0.3                  f\"λ={lambda_conf}. Corrected Risk = {max_risk.detach().cpu().numpy():.4f}\",\n",
      "   415                                                       )\n",
      "   416                                           \n",
      "   417     13071  222074364.0  16989.9      0.4              if max_risk.detach().cpu().numpy() > alpha:\n",
      "   418         4     986924.0 246731.0      0.0                  logger.info(\n",
      "   419         2      35166.0  17583.0      0.0                      f\"Solution Found: {previous_lbd} with risk {max_risk}\",\n",
      "   420                                                           )\n",
      "   421                                           \n",
      "   422         2      41799.0  20899.5      0.0                  print(\"--------------------------------------------------\")\n",
      "   423         2      13124.0   6562.0      0.0                  print(\"Lambdas\")\n",
      "   424         2      15398.0   7699.0      0.0                  print(f\"\\tprevious_lbd = {previous_lbd}\")\n",
      "   425         2      13706.0   6853.0      0.0                  print(f\"\\tLast Lambda = {lambda_conf}\")\n",
      "   426         2      14137.0   7068.5      0.0                  print(f\"\\tOther previous lbd = {self.all_lbds[-2]}\")\n",
      "   427         2      13175.0   6587.5      0.0                  print(f\"\\tOther current lbd = {self.all_lbds[-1]}\")\n",
      "   428         2      11812.0   5906.0      0.0                  print(\"All risks raw (precomputed):\")\n",
      "   429         2        381.0    190.5      0.0                  confidence_risk_raw = self.all_risks_raw_conf[-2]\n",
      "   430         2        311.0    155.5      0.0                  localization_risk_raw = self.all_risks_raw_loc[-2]\n",
      "   431         2        441.0    220.5      0.0                  classification_risk_raw = self.all_risks_raw_cls[-2]\n",
      "   432         2        350.0    175.0      0.0                  max_risk_raw = self.all_risks_raw[-2]\n",
      "   433         2      15900.0   7950.0      0.0                  print(f\"\\tConfidence Risk: {confidence_risk_raw}\")\n",
      "   434         2      14386.0   7193.0      0.0                  print(f\"\\tLocalization Risk: {localization_risk_raw}\")\n",
      "   435         2      13786.0   6893.0      0.0                  print(f\"\\tClassification Risk: {classification_risk_raw}\")\n",
      "   436         2      14918.0   7459.0      0.0                  print(f\"\\tMax Risk: {max_risk_raw}\")\n",
      "   437         2      11732.0   5866.0      0.0                  print(\"All risks monotonized (precomputed):\")\n",
      "   438         2        381.0    190.5      0.0                  confidence_risk_mon = self.all_risks_mon_conf[-2]\n",
      "   439         2        360.0    180.0      0.0                  localization_risk_mon = self.all_risks_mon_loc[-2]\n",
      "   440         2        260.0    130.0      0.0                  classification_risk_mon = self.all_risks_mon_cls[-2]\n",
      "   441         2        291.0    145.5      0.0                  max_risk_mon = self.all_risks_mon[-2]\n",
      "   442         2      13776.0   6888.0      0.0                  print(f\"\\tConfidence Risk: {confidence_risk_mon}\")\n",
      "   443         2      13275.0   6637.5      0.0                  print(f\"\\tLocalization Risk: {localization_risk_mon}\")\n",
      "   444         2      13235.0   6617.5      0.0                  print(f\"\\tClassification Risk: {classification_risk_mon}\")\n",
      "   445         2      14387.0   7193.5      0.0                  print(f\"\\tMax Risk: {max_risk_mon}\")\n",
      "   446         2      17294.0   8647.0      0.0                  print(\"Confidence risk (recomputed):\")\n",
      "   447         2        330.0    165.0      0.0                  conf_losses = []\n",
      "   448       802     148951.0    185.7      0.0                  for i in range(len(predictions)):\n",
      "   449       800     184479.0    230.6      0.0                      true_boxes_i = true_boxes[i]\n",
      "   450       800     582045.0    727.6      0.0                      pred_boxes_i = pred_boxes[i]\n",
      "   451       800    2274864.0   2843.6      0.0                      pred_cls_i = pred_cls[i]\n",
      "   452       800     128216.0    160.3      0.0                      confidences_i = confidences[i]\n",
      "   453       800     136707.0    170.9      0.0                      true_cls_i = true_cls[i]\n",
      "   454                                           \n",
      "   455       800     250322.0    312.9      0.0                      matching_i = predictions.matching[i]\n",
      "   456                                           \n",
      "   457       800   39783201.0  49729.0      0.1                      pred_boxes_i = pred_boxes_i[confidences_i >= 1 - previous_lbd]\n",
      "   458      1600  358798711.0 224249.2      0.6                      pred_cls_i = [\n",
      "   459       800   30064082.0  37580.1      0.0                          x for x, c in zip(pred_cls_i, confidences_i) if c >= 1 - previous_lbd\n",
      "   460                                                               ]\n",
      "   461      1600   36914154.0  23071.3      0.1                      confidence_loss_i = confidence_loss(\n",
      "   462       800      85883.0    107.4      0.0                          true_boxes_i,\n",
      "   463       800      74596.0     93.2      0.0                          true_cls_i,\n",
      "   464       800      81299.0    101.6      0.0                          pred_boxes_i,\n",
      "   465       800      63672.0     79.6      0.0                          pred_cls_i,\n",
      "   466                                                               )\n",
      "   467                                           \n",
      "   468       800     368989.0    461.2      0.0                      conf_losses.append(confidence_loss_i)\n",
      "   469         2     505805.0 252902.5      0.0                  conf_losses = torch.stack(conf_losses)\n",
      "   470         2     136488.0  68244.0      0.0                  print(f\"\\tConfidence Risk: {torch.mean(conf_losses)}\")\n",
      "   471         2     908525.0 454262.5      0.0                  confidence_losses = torch.stack(confidence_losses)\n",
      "   472         2      25508.0  12754.0      0.0                  print(\"Comparison of the two :\")\n",
      "   473         4      32252.0   8063.0      0.0                  print(\n",
      "   474         2    8013087.0    4e+06      0.0                      f\"\\t (isclose) {torch.isclose(conf_losses, confidence_losses).float().mean()}\",\n",
      "   475                                                           )\n",
      "   476         4      22873.0   5718.2      0.0                  print(\n",
      "   477         2     100750.0  50375.0      0.0                      f\"\\t (eq) {torch.eq(conf_losses, confidence_losses).float().mean()}\",\n",
      "   478                                                           )\n",
      "   479                                                           # now get the indices of where the losses differ, and print the image id as well as the two losses, for about 20 images\n",
      "   480         6     142700.0  23783.3      0.0                  diff_indices = torch.where(\n",
      "   481         2      28705.0  14352.5      0.0                      torch.ne(conf_losses, confidence_losses),\n",
      "   482         2        440.0    220.0      0.0                  )[0]\n",
      "   483         4      33984.0   8496.0      0.0                  for i in diff_indices[:10]:\n",
      "   484         4      33775.0   8443.8      0.0                      print(\n",
      "   485         2   18645430.0    9e+06      0.0                          f\"\\tImage {i} loss: {conf_losses[i]} (eval) vs {confidence_losses[i]} (opti)\",\n",
      "   486                                                               )\n",
      "   487         4      27403.0   6850.8      0.0                      print(\n",
      "   488         2     914506.0 457253.0      0.0                          f\"\\tImage {i} confidence: {predictions.confidences[i]}\",\n",
      "   489                                                               )\n",
      "   490                                                               # print number of ground truths\n",
      "   491         4      18516.0   4629.0      0.0                      print(\n",
      "   492         2      48061.0  24030.5      0.0                          f\"\\tImage {i} number of ground truths: {len(predictions.true_boxes[i])}\",\n",
      "   493                                                               )\n",
      "   494         4      26550.0   6637.5      0.0                      print(\n",
      "   495         2     172294.0  86147.0      0.0                          f\"\\tImage {i} number of predictions: {len(predictions.pred_boxes[i][predictions.confidences[i] >= 1 - previous_lbd])}\",\n",
      "   496                                                               )\n",
      "   497         2      15759.0   7879.5      0.0                  print(\"--------------------------------------------------\")\n",
      "   498         2       5220.0   2610.0      0.0                  return previous_lbd\n",
      "   499                                                   return lambda_conf"
     ]
    }
   ],
   "source": [
    "%lprun -f conf.confidence_conformalizer.optimizer2_minus.optimize conf.calibrate(preds_cal,alpha_confidence=0.02,alpha_localization=0.05,alpha_classification=0.05,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
