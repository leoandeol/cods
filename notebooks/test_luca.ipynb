{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c9e9aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-15 14:58:52:INFO:models.py:models:30 - __init__ ] Model detr_resnet50 initialized\n",
      "Using cache found in /home/leo.andeol/.cache/torch/hub/facebookresearch_detr_main\n",
      "/home/leo.andeol/envs/cods_13/cods/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/leo.andeol/envs/cods_13/cods/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "[2025-04-15 14:58:53:INFO:models.py:models:76 - _load_preds_if_exists ] Loading predictions from ./saved_predictions/2c92d1aaa0cc2db665dc992cc2c004015b949d723cda785c3c3a140ebe8a808b.pkl\n",
      "[2025-04-15 14:58:53:INFO:models.py:models:76 - _load_preds_if_exists ] Loading predictions from ./saved_predictions/27b7022a01eb9f119e53d0e6c2c7e9a25a4444c25cea01599ce79e2a14f06cd0.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(data) = 5000\n",
      "len(data_cal) = 400\n",
      "len(data_val) = 400\n",
      "Predictions already exist, loading them...\n",
      "Predictions already exist, loading them...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-15 14:58:53:WARNING:cp.py:cp:1488 - __init__ ] No multiple_testing_correction provided, assuming no correction is needed. The explicit list of alphas is expected for calibration.\n",
      "[2025-04-15 14:58:53:INFO:cp.py:cp:192 - __init__ ] Defaulting to CRC backend\n",
      "[2025-04-15 14:58:53:INFO:cp.py:cp:1031 - __init__ ] Defaulting to CRC backend\n",
      "[2025-04-15 14:58:53:INFO:cp.py:cp:1764 - calibrate ] Matching Predictions to True Boxes\n",
      "400it [00:00, 8450.47it/s]\n",
      "[2025-04-15 14:58:53:INFO:cp.py:cp:1777 - calibrate ] Calibrating Localization Conformalizer\n",
      "[2025-04-15 14:58:53:INFO:cp.py:cp:464 - calibrate ] Using overload confidence threshold: 0.1000\n",
      "[1.71, 1.95] -> 1.8310546875. Corrected Risk = 0.10: 100%|██████████| 13/13 [00:49<00:00,  3.78s/it]\n",
      "[2025-04-15 14:59:42:INFO:cp.py:cp:521 - calibrate ] Calibrated λ for localization: 1.8310546875\n",
      "[2025-04-15 14:59:42:INFO:cp.py:cp:1787 - calibrate ] Calibrated Localization λ : 1.8310546875\n",
      "[2025-04-15 14:59:42:INFO:cp.py:cp:1795 - calibrate ] Calibrating Classification Conformalizer\n",
      "[2025-04-15 14:59:42:INFO:cp.py:cp:1164 - calibrate ] Using overload confidence threshold: 0.1000\n",
      "[2025-04-15 14:59:42:WARNING:cp.py:cp:1169 - calibrate ] Currently considering that there is only one matching prediction to each true box for classification pruposes. To add later how to aggregate if multiple preidctions matched.\n",
      "[0.32, 0.32] -> 0.32293620705604553. Corrected Risk = 0.10: 100%|██████████| 25/25 [02:10<00:00,  5.24s/it]\n",
      "[2025-04-15 15:01:53:INFO:cp.py:cp:1237 - calibrate ] Calibrated λ for classification: 0.32293620705604553\n",
      "[2025-04-15 15:01:53:INFO:cp.py:cp:1805 - calibrate ] Calibrated Classification λ : 0.32293620705604553\n",
      "[2025-04-15 15:01:53:INFO:cp.py:cp:1847 - conformalize ] Conformalizing Predictions\n",
      "[2025-04-15 15:01:53:INFO:cp.py:cp:1850 - conformalize ] Using provided parameters for conformalization\n",
      "[2025-04-15 15:01:53:INFO:cp.py:cp:1876 - conformalize ] Using provided confidence threshold\n",
      "[2025-04-15 15:01:53:INFO:cp.py:cp:1887 - conformalize ] Conformalizing Localization\n",
      "[2025-04-15 15:01:53:INFO:cp.py:cp:566 - conformalize ] Using previous λ for localization\n",
      "[2025-04-15 15:01:53:INFO:cp.py:cp:581 - conformalize ] Conformalizing Localization with λ\n",
      "[2025-04-15 15:01:53:INFO:cp.py:cp:1898 - conformalize ] Conformalizing Classification\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence threshold is 0.1\n",
      "Matching is : True\n",
      "Matching complete\n",
      "Confidence threshold: 0.1\n",
      "ODParameters\n",
      "global_alpha: 0.23\n",
      "alpha_confidence: 0.03\n",
      "alpha_localization: 0.1\n",
      "alpha_classification: 0.1\n",
      "lambda_confidence_plus: None\n",
      "lambda_confidence_minus: None\n",
      "lambda_localization: 1.8310546875\n",
      "lambda_classification: 0.32293620705604553\n",
      "confidence_threshold: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-15 15:01:54:INFO:cp.py:cp:2015 - evaluate ] Evaluation Results:\n",
      "[2025-04-15 15:01:54:INFO:cp.py:cp:2023 - evaluate ] \t Localization:\n",
      "[2025-04-15 15:01:54:INFO:cp.py:cp:2024 - evaluate ] \t\t Risk: 0.09\n",
      "[2025-04-15 15:01:54:INFO:cp.py:cp:2025 - evaluate ] \t\t Mean Set Size: 1.08\n",
      "[2025-04-15 15:01:54:INFO:cp.py:cp:2029 - evaluate ] \t Classification:\n",
      "[2025-04-15 15:01:54:INFO:cp.py:cp:2030 - evaluate ] \t\t Risk: 0.14\n",
      "[2025-04-15 15:01:54:INFO:cp.py:cp:2031 - evaluate ] \t\t Mean Set Size: 0.64\n",
      "[2025-04-15 15:01:54:INFO:cp.py:cp:2035 - evaluate ] \t Global:\n",
      "[2025-04-15 15:01:54:INFO:cp.py:cp:2039 - evaluate ] \t\t Risk: 0.18673092126846313\n",
      "[2025-04-15 15:01:54:INFO:cp.py:cp:1847 - conformalize ] Conformalizing Predictions\n",
      "[2025-04-15 15:01:54:INFO:cp.py:cp:1850 - conformalize ] Using provided parameters for conformalization\n",
      "[2025-04-15 15:01:54:INFO:cp.py:cp:1856 - conformalize ] The parameters have been computed on another set of predictions.\n",
      "[2025-04-15 15:01:54:INFO:cp.py:cp:1876 - conformalize ] Using provided confidence threshold\n",
      "[2025-04-15 15:01:54:INFO:cp.py:cp:1887 - conformalize ] Conformalizing Localization\n",
      "[2025-04-15 15:01:54:INFO:cp.py:cp:566 - conformalize ] Using previous λ for localization\n",
      "[2025-04-15 15:01:54:INFO:cp.py:cp:581 - conformalize ] Conformalizing Localization with λ\n",
      "[2025-04-15 15:01:54:INFO:cp.py:cp:1898 - conformalize ] Conformalizing Classification\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence threshold is 0.1\n",
      "Matching is : True\n",
      "Matching complete\n",
      "Confidence threshold: 0.1\n",
      "ODParameters\n",
      "global_alpha: 0.23\n",
      "alpha_confidence: 0.03\n",
      "alpha_localization: 0.1\n",
      "alpha_classification: 0.1\n",
      "lambda_confidence_plus: None\n",
      "lambda_confidence_minus: None\n",
      "lambda_localization: 1.8310546875\n",
      "lambda_classification: 0.32293620705604553\n",
      "confidence_threshold: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-15 15:01:54:INFO:cp.py:cp:2015 - evaluate ] Evaluation Results:\n",
      "[2025-04-15 15:01:54:INFO:cp.py:cp:2023 - evaluate ] \t Localization:\n",
      "[2025-04-15 15:01:54:INFO:cp.py:cp:2024 - evaluate ] \t\t Risk: 0.12\n",
      "[2025-04-15 15:01:54:INFO:cp.py:cp:2025 - evaluate ] \t\t Mean Set Size: 1.09\n",
      "[2025-04-15 15:01:54:INFO:cp.py:cp:2029 - evaluate ] \t Classification:\n",
      "[2025-04-15 15:01:54:INFO:cp.py:cp:2030 - evaluate ] \t\t Risk: 0.15\n",
      "[2025-04-15 15:01:54:INFO:cp.py:cp:2031 - evaluate ] \t\t Mean Set Size: 0.64\n",
      "[2025-04-15 15:01:54:INFO:cp.py:cp:2035 - evaluate ] \t Global:\n",
      "[2025-04-15 15:01:54:INFO:cp.py:cp:2039 - evaluate ] \t\t Risk: 0.2156369984149933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for config alpha-[0.03, 0.1, 0.1]-mix_box_count_threshold_pixelwise_aps_additive:\n",
      "  <cods.od.data.predictions.ODResults object at 0x72a8967ca550>\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "import pickle\n",
    "import traceback\n",
    "from itertools import product\n",
    "\n",
    "from cods.od.cp import ODConformalizer\n",
    "from cods.od.data import MSCOCODataset\n",
    "from cods.od.models import DETRModel\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"  # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = (\n",
    "    \"0\"  # chose the GPU. If only one, then \"0\"\n",
    ")\n",
    "\n",
    "logging.getLogger().setLevel(logging.DEBUG)\n",
    "\n",
    "# set [COCO_PATH] to the directory to your local copy of the COCO dataset\n",
    "COCO_PATH = \"/datasets/shared_datasets/coco/\"\n",
    "\n",
    "data = MSCOCODataset(root=COCO_PATH, split=\"val\")\n",
    "\n",
    "calibration_ratio = (\n",
    "    0.5  # set 0.5 to use 50% for calibration and 50% for testing\n",
    ")\n",
    "\n",
    "use_smaller_subset = True  # TODO: Temp\n",
    "\n",
    "if use_smaller_subset:\n",
    "    data_cal, data_val = data.split_dataset(\n",
    "        calibration_ratio, shuffle=False, n_calib_test=800\n",
    "    )\n",
    "else:\n",
    "    data_cal, data_val = data.split_dataset(calibration_ratio, shuffle=True)\n",
    "\n",
    "# model and weights are downloaded from https://github.com/facebookresearch/detr\n",
    "model = DETRModel(model_name=\"detr_resnet50\", pretrained=True, device=\"cpu\")\n",
    "# model = YOLOModel(model_name=\"yolov8x.pt\", pretrained=True)\n",
    "\n",
    "\n",
    "print(f\"{len(data) = }\")\n",
    "print(f\"{len(data_cal) = }\")\n",
    "print(f\"{len(data_val) = }\")\n",
    "\n",
    "preds_cal = model.build_predictions(\n",
    "    data_cal,\n",
    "    dataset_name=\"mscoco\",\n",
    "    split_name=\"cal\",\n",
    "    batch_size=12,\n",
    "    collate_fn=data._collate_fn,  # TODO: make this a default for COCO\n",
    "    shuffle=False,\n",
    "    force_recompute=False,  # False,\n",
    "    deletion_method=\"nms\",\n",
    "    filter_preds_by_confidence=1e-3,\n",
    ")\n",
    "preds_val = model.build_predictions(\n",
    "    data_val,\n",
    "    dataset_name=\"mscoco\",\n",
    "    split_name=\"test\",\n",
    "    batch_size=12,\n",
    "    collate_fn=data._collate_fn,\n",
    "    shuffle=False,\n",
    "    force_recompute=False,  # False,\n",
    "    deletion_method=\"nms\",\n",
    "    filter_preds_by_confidence=1e-3,\n",
    ")\n",
    "\n",
    "results = {}\n",
    "\n",
    "alphas = [[0.03, 0.1, 0.1]]\n",
    "matching_functions = [\"mix\"]  # , \"hausdorff\", \"lac\"]#[\"giou\", \"hausdorff\"]\n",
    "confidence_methods = [\n",
    "    \"box_count_threshold\",\n",
    "    # \"box_count_recall\",\n",
    "    # \"box_thresholded_distance\",\n",
    "]\n",
    "localization_methods = [\"pixelwise\"]  # , \"boxwise\"]\n",
    "classification_prediction_sets = [\"aps\"]\n",
    "localization_prediction_sets = [\"additive\"]  # , \"multiplicative\"]\n",
    "\n",
    "configs = []\n",
    "for alpha in alphas:\n",
    "    for matching_function in matching_functions:\n",
    "        for confidence_method in confidence_methods:\n",
    "            for localization_method in localization_methods:\n",
    "                for (\n",
    "                    classification_prediction_set\n",
    "                ) in classification_prediction_sets:\n",
    "                    for (\n",
    "                        localization_prediction_set\n",
    "                    ) in localization_prediction_sets:\n",
    "                        configs.append(\n",
    "                            {\n",
    "                                \"alpha\": alpha,\n",
    "                                \"matching_function\": matching_function,\n",
    "                                \"confidence_method\": confidence_method,\n",
    "                                \"localization_method\": localization_method,\n",
    "                                \"classification_prediction_set\": classification_prediction_set,\n",
    "                                \"localization_prediction_set\": localization_prediction_set,\n",
    "                            }\n",
    "                        )\n",
    "for config in configs:\n",
    "    try:\n",
    "        conf = ODConformalizer(\n",
    "            guarantee_level=\"image\",\n",
    "            matching_function=config[\"matching_function\"],\n",
    "            multiple_testing_correction=None,\n",
    "            # confidence_method=config[\"confidence_method\"],\n",
    "            confidence_threshold=0.1,\n",
    "            localization_method=config[\"localization_method\"],\n",
    "            localization_prediction_set=config[\"localization_prediction_set\"],\n",
    "            classification_method=\"binary\",\n",
    "            classification_prediction_set=config[\n",
    "                \"classification_prediction_set\"\n",
    "            ],\n",
    "            backend=\"auto\",\n",
    "            optimizer=\"binary_search\",\n",
    "        )\n",
    "\n",
    "        parameters = conf.calibrate(\n",
    "            preds_cal,\n",
    "            alpha_confidence=config[\"alpha\"][0],\n",
    "            alpha_localization=config[\"alpha\"][1],\n",
    "            alpha_classification=config[\"alpha\"][2],\n",
    "        )\n",
    "\n",
    "        conformal_preds_cal = conf.conformalize(\n",
    "            preds_cal, parameters=parameters\n",
    "        )\n",
    "\n",
    "        results_cal = conf.evaluate(\n",
    "            preds_cal,\n",
    "            parameters=parameters,\n",
    "            conformalized_predictions=conformal_preds_cal,\n",
    "            include_confidence_in_global=False,\n",
    "        )\n",
    "\n",
    "        conformal_preds = conf.conformalize(preds_val, parameters=parameters)\n",
    "\n",
    "        results_val = conf.evaluate(\n",
    "            preds_val,\n",
    "            parameters=parameters,\n",
    "            conformalized_predictions=conformal_preds,\n",
    "            include_confidence_in_global=False,\n",
    "        )\n",
    "\n",
    "        config_str = f\"alpha-{config['alpha']}-{config['matching_function']}_{config['confidence_method']}_{config['localization_method']}_{config['classification_prediction_set']}_{config['localization_prediction_set']}\"\n",
    "\n",
    "        results[config_str] = results_val\n",
    "\n",
    "        print(f\"Results for config {config_str}:\")\n",
    "        print(f\"  {results_val}\")\n",
    "        # Save results to a pickle file\n",
    "    except Exception as e:\n",
    "        print(f\"Error with config {config}: {e}\")\n",
    "        print(traceback.format_exc())\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8e5ef31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-17 03:32:57:INFO:models.py:models:30 - __init__ ] Model detr_resnet50 initialized\n",
      "Using cache found in /home/leo.andeol/.cache/torch/hub/facebookresearch_detr_main\n",
      "/home/leo.andeol/envs/cods_13/cods/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/leo.andeol/envs/cods_13/cods/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "[2025-04-17 03:33:01:INFO:models.py:models:76 - _load_preds_if_exists ] Loading predictions from ./saved_predictions/2c92d1aaa0cc2db665dc992cc2c004015b949d723cda785c3c3a140ebe8a808b.pkl\n",
      "[2025-04-17 03:33:01:INFO:models.py:models:76 - _load_preds_if_exists ] Loading predictions from ./saved_predictions/27b7022a01eb9f119e53d0e6c2c7e9a25a4444c25cea01599ce79e2a14f06cd0.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(data) = 5000\n",
      "len(data_cal) = 400\n",
      "len(data_val) = 400\n",
      "Predictions already exist, loading them...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-17 03:33:01:WARNING:cp.py:cp:1489 - __init__ ] No multiple_testing_correction provided, assuming no correction is needed. The explicit list of alphas is expected for calibration.\n",
      "[2025-04-17 03:33:01:INFO:cp.py:cp:192 - __init__ ] Defaulting to CRC backend\n",
      "[2025-04-17 03:33:01:INFO:cp.py:cp:1031 - __init__ ] Defaulting to CRC backend\n",
      "[2025-04-17 03:33:01:INFO:cp.py:cp:1729 - calibrate ] Calibrating Confidence Conformalizer\n",
      "[2025-04-17 03:33:01:DEBUG:cp.py:cp:822 - calibrate ] Optimizing for lambda_plus\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions already exist, loading them...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/400 [00:00<?, ?it/s]/home/leo.andeol/envs/cods_13/cods/cods/od/utils.py:424: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
      "  Qst = torch.FloatTensor([Qs]).to(device)\n",
      "100%|██████████| 400/400 [00:00<00:00, 1451.47it/s]\n",
      "[2025-04-17 03:33:01:DEBUG:optim.py:optim:205 - optimize ] Risk after 1st epoch is 0.004987531341612339 < 0.03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First risk: 0.004987531341612339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "λ=0.9864142537117004. Corrected Risk = 0.0324:  24%|██▍       | 3206/13249 [00:05<00:18, 531.29it/s][2025-04-17 03:33:07:INFO:optim.py:optim:407 - optimize ] Solution Found: 0.9864242672920227 with risk 0.03241895139217377\n",
      "λ=0.9864142537117004. Corrected Risk = 0.0324:  24%|██▍       | 3228/13249 [00:05<00:17, 576.66it/s]\n",
      "[2025-04-17 03:33:07:DEBUG:cp.py:cp:836 - calibrate ] Optimizing for lambda_minus\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Lambdas\n",
      "\tprevious_lbd = 0.9864242672920227\n",
      "\tLast Lambda = 0.9864142537117004\n",
      "\tOther previous lbd = 0.9864242672920227\n",
      "\tOther current lbd = 0.9864142537117004\n",
      "All risks raw (precomputed):\n",
      "\tConfidence Risk: 0.029925186187028885\n",
      "\tLocalization Risk: 0.0024937656708061695\n",
      "\tClassification Risk: 0.0024937656708061695\n",
      "\tMax Risk: 0.029925186187028885\n",
      "All risks monotonized (precomputed):\n",
      "\tConfidence Risk: 0.029925186187028885\n",
      "\tLocalization Risk: 0.0024937656708061695\n",
      "\tClassification Risk: 0.0024937656708061695\n",
      "\tMax Risk: 0.029925186187028885\n",
      "Confidence risk (recomputed):\n",
      "\tConfidence Risk: 0.027499999850988388\n",
      "Comparison of the two :\n",
      "\t (isclose) 0.9975000023841858\n",
      "\t (eq) 0.9975000023841858\n",
      "\tImage 199 loss: tensor([0.]) (eval) vs tensor([1.]) (opti)\n",
      "\tImage 199 confidence: tensor([0.9999, 0.9984, 0.0136, 0.0072, 0.0059, 0.0032, 0.0015])\n",
      "\tImage 199 number of ground truths: 3\n",
      "\tImage 199 number of predictions: 3\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [00:00<00:00, 1337.88it/s]\n",
      "[2025-04-17 03:33:08:DEBUG:optim.py:optim:205 - optimize ] Risk after 1st epoch is 0.0024937656708061695 < 0.03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First risk: 0.0024937656708061695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "λ=0.9846566915512085. Corrected Risk = 0.0324:  26%|██▌       | 3383/13249 [00:06<00:18, 527.13it/s][2025-04-17 03:33:14:INFO:optim.py:optim:407 - optimize ] Solution Found: 0.9846822023391724 with risk 0.03241895139217377\n",
      "λ=0.9846566915512085. Corrected Risk = 0.0324:  26%|██▌       | 3425/13249 [00:06<00:17, 558.66it/s]\n",
      "[2025-04-17 03:33:14:INFO:cp.py:cp:1739 - calibrate ] Setting Confidence Threshold of Predictions\n",
      "[2025-04-17 03:33:14:INFO:cp.py:cp:1750 - calibrate ] Calibrated Confidence λ : 0.9864\n",
      "\t and associated Confidence Threshold : 0.013575732707977295\n",
      "[2025-04-17 03:33:14:INFO:cp.py:cp:1765 - calibrate ] Matching Predictions to True Boxes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Lambdas\n",
      "\tprevious_lbd = 0.9846822023391724\n",
      "\tLast Lambda = 0.9846566915512085\n",
      "\tOther previous lbd = 0.9846822023391724\n",
      "\tOther current lbd = 0.9846566915512085\n",
      "All risks raw (precomputed):\n",
      "\tConfidence Risk: 0.029925186187028885\n",
      "\tLocalization Risk: 0.0\n",
      "\tClassification Risk: 0.0\n",
      "\tMax Risk: 0.029925186187028885\n",
      "All risks monotonized (precomputed):\n",
      "\tConfidence Risk: 0.029925186187028885\n",
      "\tLocalization Risk: 0.0\n",
      "\tClassification Risk: 0.0\n",
      "\tMax Risk: 0.029925186187028885\n",
      "Confidence risk (recomputed):\n",
      "\tConfidence Risk: 0.029999999329447746\n",
      "Comparison of the two :\n",
      "\t (isclose) 0.9975000023841858\n",
      "\t (eq) 0.9975000023841858\n",
      "\tImage 225 loss: tensor([0.]) (eval) vs tensor([1.]) (opti)\n",
      "\tImage 225 confidence: tensor([0.9996, 0.1580, 0.0153, 0.0152, 0.0069, 0.0025, 0.0013, 0.0013])\n",
      "\tImage 225 number of ground truths: 3\n",
      "\tImage 225 number of predictions: 3\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "400it [00:00, 8315.60it/s]\n",
      "[2025-04-17 03:33:14:INFO:cp.py:cp:1778 - calibrate ] Calibrating Localization Conformalizer\n",
      "[2025-04-17 03:33:14:INFO:cp.py:cp:464 - calibrate ] Using overload confidence threshold: 0.0153\n",
      "[1.22, 1.46] -> λ=1.3427734375. Corrected Risk = 0.10: 100%|██████████| 13/13 [00:21<00:00,  1.69s/it]\n",
      "[2025-04-17 03:33:36:INFO:cp.py:cp:521 - calibrate ] Calibrated λ for localization: 1.3427734375\n",
      "[2025-04-17 03:33:36:INFO:cp.py:cp:1788 - calibrate ] Calibrated Localization λ : 1.3427734375\n",
      "[2025-04-17 03:33:36:INFO:cp.py:cp:1796 - calibrate ] Calibrating Classification Conformalizer\n",
      "[2025-04-17 03:33:36:INFO:cp.py:cp:1164 - calibrate ] Using overload confidence threshold: 0.0153\n",
      "[2025-04-17 03:33:36:WARNING:cp.py:cp:1169 - calibrate ] Currently considering that there is only one matching prediction to each true box for classification pruposes. To add later how to aggregate if multiple preidctions matched.\n",
      "[0.91, 0.91] -> λ=0.906660407781601. Corrected Risk = 0.10: 100%|██████████| 25/25 [01:02<00:00,  2.50s/it] \n",
      "[2025-04-17 03:34:39:INFO:cp.py:cp:1238 - calibrate ] Calibrated λ for classification: 0.906660407781601\n",
      "[2025-04-17 03:34:39:INFO:cp.py:cp:1806 - calibrate ] Calibrated Classification λ : 0.906660407781601\n",
      "[2025-04-17 03:34:39:INFO:cp.py:cp:1848 - conformalize ] Conformalizing Predictions\n",
      "[2025-04-17 03:34:39:INFO:cp.py:cp:1851 - conformalize ] Using provided parameters for conformalization\n",
      "[2025-04-17 03:34:39:INFO:cp.py:cp:1869 - conformalize ] Conformalizing Confidence\n",
      "[2025-04-17 03:34:39:INFO:cp.py:cp:1888 - conformalize ] Conformalizing Localization\n",
      "[2025-04-17 03:34:39:INFO:cp.py:cp:566 - conformalize ] Using previous λ for localization\n",
      "[2025-04-17 03:34:39:INFO:cp.py:cp:581 - conformalize ] Conformalizing Localization with λ\n",
      "[2025-04-17 03:34:39:INFO:cp.py:cp:1899 - conformalize ] Conformalizing Classification\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence threshold is 0.013575732707977295\n",
      "Matching is : True\n",
      "Matching complete\n",
      "Confidence threshold: 0.013575732707977295\n",
      "ODParameters\n",
      "global_alpha: 0.23\n",
      "alpha_confidence: 0.03\n",
      "alpha_localization: 0.1\n",
      "alpha_classification: 0.1\n",
      "lambda_confidence_plus: 0.9864242672920227\n",
      "lambda_confidence_minus: 0.9846822023391724\n",
      "lambda_localization: 1.3427734375\n",
      "lambda_classification: 0.906660407781601\n",
      "confidence_threshold: 0.013575732707977295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-17 03:34:39:INFO:cp.py:cp:2016 - evaluate ] Evaluation Results:\n",
      "[2025-04-17 03:34:39:INFO:cp.py:cp:2018 - evaluate ] \t Confidence:\n",
      "[2025-04-17 03:34:39:INFO:cp.py:cp:2019 - evaluate ] \t\t Risk: 0.03\n",
      "[2025-04-17 03:34:39:INFO:cp.py:cp:2020 - evaluate ] \t\t Mean Set Size: 25.06\n",
      "[2025-04-17 03:34:39:INFO:cp.py:cp:2024 - evaluate ] \t Localization:\n",
      "[2025-04-17 03:34:39:INFO:cp.py:cp:2025 - evaluate ] \t\t Risk: 0.10\n",
      "[2025-04-17 03:34:39:INFO:cp.py:cp:2026 - evaluate ] \t\t Mean Set Size: 1.07\n",
      "[2025-04-17 03:34:39:INFO:cp.py:cp:2030 - evaluate ] \t Classification:\n",
      "[2025-04-17 03:34:39:INFO:cp.py:cp:2031 - evaluate ] \t\t Risk: 0.10\n",
      "[2025-04-17 03:34:39:INFO:cp.py:cp:2032 - evaluate ] \t\t Mean Set Size: 0.70\n",
      "[2025-04-17 03:34:39:INFO:cp.py:cp:2036 - evaluate ] \t Global:\n",
      "[2025-04-17 03:34:39:INFO:cp.py:cp:2040 - evaluate ] \t\t Risk: 0.1638501137495041\n",
      "[2025-04-17 03:34:39:INFO:cp.py:cp:1848 - conformalize ] Conformalizing Predictions\n",
      "[2025-04-17 03:34:39:INFO:cp.py:cp:1851 - conformalize ] Using provided parameters for conformalization\n",
      "[2025-04-17 03:34:39:INFO:cp.py:cp:1857 - conformalize ] The parameters have been computed on another set of predictions.\n",
      "[2025-04-17 03:34:39:INFO:cp.py:cp:1869 - conformalize ] Conformalizing Confidence\n",
      "[2025-04-17 03:34:39:INFO:cp.py:cp:1888 - conformalize ] Conformalizing Localization\n",
      "[2025-04-17 03:34:39:INFO:cp.py:cp:566 - conformalize ] Using previous λ for localization\n",
      "[2025-04-17 03:34:39:INFO:cp.py:cp:581 - conformalize ] Conformalizing Localization with λ\n",
      "[2025-04-17 03:34:39:INFO:cp.py:cp:1899 - conformalize ] Conformalizing Classification\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence threshold is 0.013575732707977295\n",
      "Matching is : True\n",
      "Matching complete\n",
      "Confidence threshold: 0.013575732707977295\n",
      "ODParameters\n",
      "global_alpha: 0.23\n",
      "alpha_confidence: 0.03\n",
      "alpha_localization: 0.1\n",
      "alpha_classification: 0.1\n",
      "lambda_confidence_plus: 0.9864242672920227\n",
      "lambda_confidence_minus: 0.9846822023391724\n",
      "lambda_localization: 1.3427734375\n",
      "lambda_classification: 0.906660407781601\n",
      "confidence_threshold: 0.013575732707977295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-17 03:34:40:INFO:cp.py:cp:2016 - evaluate ] Evaluation Results:\n",
      "[2025-04-17 03:34:40:INFO:cp.py:cp:2018 - evaluate ] \t Confidence:\n",
      "[2025-04-17 03:34:40:INFO:cp.py:cp:2019 - evaluate ] \t\t Risk: 0.03\n",
      "[2025-04-17 03:34:40:INFO:cp.py:cp:2020 - evaluate ] \t\t Mean Set Size: 28.26\n",
      "[2025-04-17 03:34:40:INFO:cp.py:cp:2024 - evaluate ] \t Localization:\n",
      "[2025-04-17 03:34:40:INFO:cp.py:cp:2025 - evaluate ] \t\t Risk: 0.12\n",
      "[2025-04-17 03:34:40:INFO:cp.py:cp:2026 - evaluate ] \t\t Mean Set Size: 1.08\n",
      "[2025-04-17 03:34:40:INFO:cp.py:cp:2030 - evaluate ] \t Classification:\n",
      "[2025-04-17 03:34:40:INFO:cp.py:cp:2031 - evaluate ] \t\t Risk: 0.10\n",
      "[2025-04-17 03:34:40:INFO:cp.py:cp:2032 - evaluate ] \t\t Mean Set Size: 0.71\n",
      "[2025-04-17 03:34:40:INFO:cp.py:cp:2036 - evaluate ] \t Global:\n",
      "[2025-04-17 03:34:40:INFO:cp.py:cp:2040 - evaluate ] \t\t Risk: 0.18737010657787323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for config alpha-[0.03, 0.1, 0.1]-mix_box_count_threshold_pixelwise_aps_additive:\n",
      "  <cods.od.data.predictions.ODResults object at 0x7ab85990ef50>\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "import pickle\n",
    "import traceback\n",
    "from itertools import product\n",
    "\n",
    "from cods.od.cp import ODConformalizer\n",
    "from cods.od.data import MSCOCODataset\n",
    "from cods.od.models import DETRModel\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"  # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = (\n",
    "    \"0\"  # chose the GPU. If only one, then \"0\"\n",
    ")\n",
    "\n",
    "logging.getLogger().setLevel(logging.DEBUG)\n",
    "\n",
    "# set [COCO_PATH] to the directory to your local copy of the COCO dataset\n",
    "COCO_PATH = \"/datasets/shared_datasets/coco/\"\n",
    "\n",
    "data = MSCOCODataset(root=COCO_PATH, split=\"val\")\n",
    "\n",
    "calibration_ratio = (\n",
    "    0.5  # set 0.5 to use 50% for calibration and 50% for testing\n",
    ")\n",
    "\n",
    "use_smaller_subset = True  # TODO: Temp\n",
    "\n",
    "if use_smaller_subset:\n",
    "    data_cal, data_val = data.split_dataset(\n",
    "        calibration_ratio, shuffle=False, n_calib_test=800\n",
    "    )\n",
    "else:\n",
    "    data_cal, data_val = data.split_dataset(calibration_ratio, shuffle=True)\n",
    "\n",
    "# model and weights are downloaded from https://github.com/facebookresearch/detr\n",
    "model = DETRModel(model_name=\"detr_resnet50\", pretrained=True, device=\"cpu\")\n",
    "# model = YOLOModel(model_name=\"yolov8x.pt\", pretrained=True)\n",
    "\n",
    "\n",
    "print(f\"{len(data) = }\")\n",
    "print(f\"{len(data_cal) = }\")\n",
    "print(f\"{len(data_val) = }\")\n",
    "\n",
    "preds_cal = model.build_predictions(\n",
    "    data_cal,\n",
    "    dataset_name=\"mscoco\",\n",
    "    split_name=\"cal\",\n",
    "    batch_size=12,\n",
    "    collate_fn=data._collate_fn,  # TODO: make this a default for COCO\n",
    "    shuffle=False,\n",
    "    force_recompute=False,  # False,\n",
    "    deletion_method=\"nms\",\n",
    "    filter_preds_by_confidence=1e-3,\n",
    ")\n",
    "preds_val = model.build_predictions(\n",
    "    data_val,\n",
    "    dataset_name=\"mscoco\",\n",
    "    split_name=\"test\",\n",
    "    batch_size=12,\n",
    "    collate_fn=data._collate_fn,\n",
    "    shuffle=False,\n",
    "    force_recompute=False,  # False,\n",
    "    deletion_method=\"nms\",\n",
    "    filter_preds_by_confidence=1e-3,\n",
    ")\n",
    "\n",
    "results = {}\n",
    "\n",
    "alphas = [[0.03, 0.1, 0.1]]\n",
    "matching_functions = [\"mix\"]  # , \"hausdorff\", \"lac\"]#[\"giou\", \"hausdorff\"]\n",
    "confidence_methods = [\n",
    "    \"box_count_threshold\",\n",
    "    # \"box_count_recall\",\n",
    "    # \"box_thresholded_distance\",\n",
    "]\n",
    "localization_methods = [\"pixelwise\"]  # , \"boxwise\"]\n",
    "classification_prediction_sets = [\"aps\"]\n",
    "localization_prediction_sets = [\"additive\"]  # , \"multiplicative\"]\n",
    "\n",
    "configs = []\n",
    "for alpha in alphas:\n",
    "    for matching_function in matching_functions:\n",
    "        for confidence_method in confidence_methods:\n",
    "            for localization_method in localization_methods:\n",
    "                for (\n",
    "                    classification_prediction_set\n",
    "                ) in classification_prediction_sets:\n",
    "                    for (\n",
    "                        localization_prediction_set\n",
    "                    ) in localization_prediction_sets:\n",
    "                        configs.append(\n",
    "                            {\n",
    "                                \"alpha\": alpha,\n",
    "                                \"matching_function\": matching_function,\n",
    "                                \"confidence_method\": confidence_method,\n",
    "                                \"localization_method\": localization_method,\n",
    "                                \"classification_prediction_set\": classification_prediction_set,\n",
    "                                \"localization_prediction_set\": localization_prediction_set,\n",
    "                            }\n",
    "                        )\n",
    "for config in configs:\n",
    "    try:\n",
    "        conf = ODConformalizer(\n",
    "            guarantee_level=\"image\",\n",
    "            matching_function=config[\"matching_function\"],\n",
    "            multiple_testing_correction=None,\n",
    "            confidence_method=config[\"confidence_method\"],\n",
    "            # confidence_threshold=0.1,\n",
    "            localization_method=config[\"localization_method\"],\n",
    "            localization_prediction_set=config[\"localization_prediction_set\"],\n",
    "            classification_method=\"binary\",\n",
    "            classification_prediction_set=config[\n",
    "                \"classification_prediction_set\"\n",
    "            ],\n",
    "            backend=\"auto\",\n",
    "            optimizer=\"binary_search\",\n",
    "        )\n",
    "\n",
    "        parameters = conf.calibrate(\n",
    "            preds_cal,\n",
    "            alpha_confidence=config[\"alpha\"][0],\n",
    "            alpha_localization=config[\"alpha\"][1],\n",
    "            alpha_classification=config[\"alpha\"][2],\n",
    "        )\n",
    "\n",
    "        conformal_preds_cal = conf.conformalize(\n",
    "            preds_cal, parameters=parameters\n",
    "        )\n",
    "\n",
    "        results_cal = conf.evaluate(\n",
    "            preds_cal,\n",
    "            parameters=parameters,\n",
    "            conformalized_predictions=conformal_preds_cal,\n",
    "            include_confidence_in_global=False,\n",
    "        )\n",
    "\n",
    "        conformal_preds = conf.conformalize(preds_val, parameters=parameters)\n",
    "\n",
    "        results_val = conf.evaluate(\n",
    "            preds_val,\n",
    "            parameters=parameters,\n",
    "            conformalized_predictions=conformal_preds,\n",
    "            include_confidence_in_global=False,\n",
    "        )\n",
    "\n",
    "        config_str = f\"alpha-{config['alpha']}-{config['matching_function']}_{config['confidence_method']}_{config['localization_method']}_{config['classification_prediction_set']}_{config['localization_prediction_set']}\"\n",
    "\n",
    "        results[config_str] = results_val\n",
    "\n",
    "        print(f\"Results for config {config_str}:\")\n",
    "        print(f\"  {results_val}\")\n",
    "        # Save results to a pickle file\n",
    "    except Exception as e:\n",
    "        print(f\"Error with config {config}: {e}\")\n",
    "        print(traceback.format_exc())\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219d3b31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
