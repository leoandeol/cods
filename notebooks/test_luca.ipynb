{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c9e9aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-15 14:58:52:INFO:models.py:models:30 - __init__ ] Model detr_resnet50 initialized\n",
      "Using cache found in /home/leo.andeol/.cache/torch/hub/facebookresearch_detr_main\n",
      "/home/leo.andeol/envs/cods_13/cods/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/leo.andeol/envs/cods_13/cods/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "[2025-04-15 14:58:53:INFO:models.py:models:76 - _load_preds_if_exists ] Loading predictions from ./saved_predictions/2c92d1aaa0cc2db665dc992cc2c004015b949d723cda785c3c3a140ebe8a808b.pkl\n",
      "[2025-04-15 14:58:53:INFO:models.py:models:76 - _load_preds_if_exists ] Loading predictions from ./saved_predictions/27b7022a01eb9f119e53d0e6c2c7e9a25a4444c25cea01599ce79e2a14f06cd0.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(data) = 5000\n",
      "len(data_cal) = 400\n",
      "len(data_val) = 400\n",
      "Predictions already exist, loading them...\n",
      "Predictions already exist, loading them...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-15 14:58:53:WARNING:cp.py:cp:1488 - __init__ ] No multiple_testing_correction provided, assuming no correction is needed. The explicit list of alphas is expected for calibration.\n",
      "[2025-04-15 14:58:53:INFO:cp.py:cp:192 - __init__ ] Defaulting to CRC backend\n",
      "[2025-04-15 14:58:53:INFO:cp.py:cp:1031 - __init__ ] Defaulting to CRC backend\n",
      "[2025-04-15 14:58:53:INFO:cp.py:cp:1764 - calibrate ] Matching Predictions to True Boxes\n",
      "400it [00:00, 8450.47it/s]\n",
      "[2025-04-15 14:58:53:INFO:cp.py:cp:1777 - calibrate ] Calibrating Localization Conformalizer\n",
      "[2025-04-15 14:58:53:INFO:cp.py:cp:464 - calibrate ] Using overload confidence threshold: 0.1000\n",
      "[1.71, 1.95] -> 1.8310546875. Corrected Risk = 0.10: 100%|██████████| 13/13 [00:49<00:00,  3.78s/it]\n",
      "[2025-04-15 14:59:42:INFO:cp.py:cp:521 - calibrate ] Calibrated λ for localization: 1.8310546875\n",
      "[2025-04-15 14:59:42:INFO:cp.py:cp:1787 - calibrate ] Calibrated Localization λ : 1.8310546875\n",
      "[2025-04-15 14:59:42:INFO:cp.py:cp:1795 - calibrate ] Calibrating Classification Conformalizer\n",
      "[2025-04-15 14:59:42:INFO:cp.py:cp:1164 - calibrate ] Using overload confidence threshold: 0.1000\n",
      "[2025-04-15 14:59:42:WARNING:cp.py:cp:1169 - calibrate ] Currently considering that there is only one matching prediction to each true box for classification pruposes. To add later how to aggregate if multiple preidctions matched.\n",
      "[0.32, 0.32] -> 0.32293620705604553. Corrected Risk = 0.10: 100%|██████████| 25/25 [02:10<00:00,  5.24s/it]\n",
      "[2025-04-15 15:01:53:INFO:cp.py:cp:1237 - calibrate ] Calibrated λ for classification: 0.32293620705604553\n",
      "[2025-04-15 15:01:53:INFO:cp.py:cp:1805 - calibrate ] Calibrated Classification λ : 0.32293620705604553\n",
      "[2025-04-15 15:01:53:INFO:cp.py:cp:1847 - conformalize ] Conformalizing Predictions\n",
      "[2025-04-15 15:01:53:INFO:cp.py:cp:1850 - conformalize ] Using provided parameters for conformalization\n",
      "[2025-04-15 15:01:53:INFO:cp.py:cp:1876 - conformalize ] Using provided confidence threshold\n",
      "[2025-04-15 15:01:53:INFO:cp.py:cp:1887 - conformalize ] Conformalizing Localization\n",
      "[2025-04-15 15:01:53:INFO:cp.py:cp:566 - conformalize ] Using previous λ for localization\n",
      "[2025-04-15 15:01:53:INFO:cp.py:cp:581 - conformalize ] Conformalizing Localization with λ\n",
      "[2025-04-15 15:01:53:INFO:cp.py:cp:1898 - conformalize ] Conformalizing Classification\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence threshold is 0.1\n",
      "Matching is : True\n",
      "Matching complete\n",
      "Confidence threshold: 0.1\n",
      "ODParameters\n",
      "global_alpha: 0.23\n",
      "alpha_confidence: 0.03\n",
      "alpha_localization: 0.1\n",
      "alpha_classification: 0.1\n",
      "lambda_confidence_plus: None\n",
      "lambda_confidence_minus: None\n",
      "lambda_localization: 1.8310546875\n",
      "lambda_classification: 0.32293620705604553\n",
      "confidence_threshold: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-15 15:01:54:INFO:cp.py:cp:2015 - evaluate ] Evaluation Results:\n",
      "[2025-04-15 15:01:54:INFO:cp.py:cp:2023 - evaluate ] \t Localization:\n",
      "[2025-04-15 15:01:54:INFO:cp.py:cp:2024 - evaluate ] \t\t Risk: 0.09\n",
      "[2025-04-15 15:01:54:INFO:cp.py:cp:2025 - evaluate ] \t\t Mean Set Size: 1.08\n",
      "[2025-04-15 15:01:54:INFO:cp.py:cp:2029 - evaluate ] \t Classification:\n",
      "[2025-04-15 15:01:54:INFO:cp.py:cp:2030 - evaluate ] \t\t Risk: 0.14\n",
      "[2025-04-15 15:01:54:INFO:cp.py:cp:2031 - evaluate ] \t\t Mean Set Size: 0.64\n",
      "[2025-04-15 15:01:54:INFO:cp.py:cp:2035 - evaluate ] \t Global:\n",
      "[2025-04-15 15:01:54:INFO:cp.py:cp:2039 - evaluate ] \t\t Risk: 0.18673092126846313\n",
      "[2025-04-15 15:01:54:INFO:cp.py:cp:1847 - conformalize ] Conformalizing Predictions\n",
      "[2025-04-15 15:01:54:INFO:cp.py:cp:1850 - conformalize ] Using provided parameters for conformalization\n",
      "[2025-04-15 15:01:54:INFO:cp.py:cp:1856 - conformalize ] The parameters have been computed on another set of predictions.\n",
      "[2025-04-15 15:01:54:INFO:cp.py:cp:1876 - conformalize ] Using provided confidence threshold\n",
      "[2025-04-15 15:01:54:INFO:cp.py:cp:1887 - conformalize ] Conformalizing Localization\n",
      "[2025-04-15 15:01:54:INFO:cp.py:cp:566 - conformalize ] Using previous λ for localization\n",
      "[2025-04-15 15:01:54:INFO:cp.py:cp:581 - conformalize ] Conformalizing Localization with λ\n",
      "[2025-04-15 15:01:54:INFO:cp.py:cp:1898 - conformalize ] Conformalizing Classification\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence threshold is 0.1\n",
      "Matching is : True\n",
      "Matching complete\n",
      "Confidence threshold: 0.1\n",
      "ODParameters\n",
      "global_alpha: 0.23\n",
      "alpha_confidence: 0.03\n",
      "alpha_localization: 0.1\n",
      "alpha_classification: 0.1\n",
      "lambda_confidence_plus: None\n",
      "lambda_confidence_minus: None\n",
      "lambda_localization: 1.8310546875\n",
      "lambda_classification: 0.32293620705604553\n",
      "confidence_threshold: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-15 15:01:54:INFO:cp.py:cp:2015 - evaluate ] Evaluation Results:\n",
      "[2025-04-15 15:01:54:INFO:cp.py:cp:2023 - evaluate ] \t Localization:\n",
      "[2025-04-15 15:01:54:INFO:cp.py:cp:2024 - evaluate ] \t\t Risk: 0.12\n",
      "[2025-04-15 15:01:54:INFO:cp.py:cp:2025 - evaluate ] \t\t Mean Set Size: 1.09\n",
      "[2025-04-15 15:01:54:INFO:cp.py:cp:2029 - evaluate ] \t Classification:\n",
      "[2025-04-15 15:01:54:INFO:cp.py:cp:2030 - evaluate ] \t\t Risk: 0.15\n",
      "[2025-04-15 15:01:54:INFO:cp.py:cp:2031 - evaluate ] \t\t Mean Set Size: 0.64\n",
      "[2025-04-15 15:01:54:INFO:cp.py:cp:2035 - evaluate ] \t Global:\n",
      "[2025-04-15 15:01:54:INFO:cp.py:cp:2039 - evaluate ] \t\t Risk: 0.2156369984149933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for config alpha-[0.03, 0.1, 0.1]-mix_box_count_threshold_pixelwise_aps_additive:\n",
      "  <cods.od.data.predictions.ODResults object at 0x72a8967ca550>\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "import pickle\n",
    "import traceback\n",
    "from itertools import product\n",
    "\n",
    "from cods.od.cp import ODConformalizer\n",
    "from cods.od.data import MSCOCODataset\n",
    "from cods.od.models import DETRModel\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"  # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = (\n",
    "    \"0\"  # chose the GPU. If only one, then \"0\"\n",
    ")\n",
    "\n",
    "logging.getLogger().setLevel(logging.DEBUG)\n",
    "\n",
    "# set [COCO_PATH] to the directory to your local copy of the COCO dataset\n",
    "COCO_PATH = \"/datasets/shared_datasets/coco/\"\n",
    "\n",
    "data = MSCOCODataset(root=COCO_PATH, split=\"val\")\n",
    "\n",
    "calibration_ratio = (\n",
    "    0.5  # set 0.5 to use 50% for calibration and 50% for testing\n",
    ")\n",
    "\n",
    "use_smaller_subset = True  # TODO: Temp\n",
    "\n",
    "if use_smaller_subset:\n",
    "    data_cal, data_val = data.split_dataset(\n",
    "        calibration_ratio, shuffle=False, n_calib_test=800\n",
    "    )\n",
    "else:\n",
    "    data_cal, data_val = data.split_dataset(calibration_ratio, shuffle=True)\n",
    "\n",
    "# model and weights are downloaded from https://github.com/facebookresearch/detr\n",
    "model = DETRModel(model_name=\"detr_resnet50\", pretrained=True, device=\"cpu\")\n",
    "# model = YOLOModel(model_name=\"yolov8x.pt\", pretrained=True)\n",
    "\n",
    "\n",
    "print(f\"{len(data) = }\")\n",
    "print(f\"{len(data_cal) = }\")\n",
    "print(f\"{len(data_val) = }\")\n",
    "\n",
    "preds_cal = model.build_predictions(\n",
    "    data_cal,\n",
    "    dataset_name=\"mscoco\",\n",
    "    split_name=\"cal\",\n",
    "    batch_size=12,\n",
    "    collate_fn=data._collate_fn,  # TODO: make this a default for COCO\n",
    "    shuffle=False,\n",
    "    force_recompute=False,  # False,\n",
    "    deletion_method=\"nms\",\n",
    "    filter_preds_by_confidence=1e-3,\n",
    ")\n",
    "preds_val = model.build_predictions(\n",
    "    data_val,\n",
    "    dataset_name=\"mscoco\",\n",
    "    split_name=\"test\",\n",
    "    batch_size=12,\n",
    "    collate_fn=data._collate_fn,\n",
    "    shuffle=False,\n",
    "    force_recompute=False,  # False,\n",
    "    deletion_method=\"nms\",\n",
    "    filter_preds_by_confidence=1e-3,\n",
    ")\n",
    "\n",
    "results = {}\n",
    "\n",
    "alphas = [[0.03, 0.1, 0.1]]\n",
    "matching_functions = [\"mix\"]  # , \"hausdorff\", \"lac\"]#[\"giou\", \"hausdorff\"]\n",
    "confidence_methods = [\n",
    "    \"box_count_threshold\",\n",
    "    # \"box_count_recall\",\n",
    "    # \"box_thresholded_distance\",\n",
    "]\n",
    "localization_methods = [\"pixelwise\"]  # , \"boxwise\"]\n",
    "classification_prediction_sets = [\"aps\"]\n",
    "localization_prediction_sets = [\"additive\"]  # , \"multiplicative\"]\n",
    "\n",
    "configs = []\n",
    "for alpha in alphas:\n",
    "    for matching_function in matching_functions:\n",
    "        for confidence_method in confidence_methods:\n",
    "            for localization_method in localization_methods:\n",
    "                for (\n",
    "                    classification_prediction_set\n",
    "                ) in classification_prediction_sets:\n",
    "                    for (\n",
    "                        localization_prediction_set\n",
    "                    ) in localization_prediction_sets:\n",
    "                        configs.append(\n",
    "                            {\n",
    "                                \"alpha\": alpha,\n",
    "                                \"matching_function\": matching_function,\n",
    "                                \"confidence_method\": confidence_method,\n",
    "                                \"localization_method\": localization_method,\n",
    "                                \"classification_prediction_set\": classification_prediction_set,\n",
    "                                \"localization_prediction_set\": localization_prediction_set,\n",
    "                            }\n",
    "                        )\n",
    "for config in configs:\n",
    "    try:\n",
    "        conf = ODConformalizer(\n",
    "            guarantee_level=\"image\",\n",
    "            matching_function=config[\"matching_function\"],\n",
    "            multiple_testing_correction=None,\n",
    "            # confidence_method=config[\"confidence_method\"],\n",
    "            confidence_threshold=0.1,\n",
    "            localization_method=config[\"localization_method\"],\n",
    "            localization_prediction_set=config[\"localization_prediction_set\"],\n",
    "            classification_method=\"binary\",\n",
    "            classification_prediction_set=config[\n",
    "                \"classification_prediction_set\"\n",
    "            ],\n",
    "            backend=\"auto\",\n",
    "            optimizer=\"binary_search\",\n",
    "        )\n",
    "\n",
    "        parameters = conf.calibrate(\n",
    "            preds_cal,\n",
    "            alpha_confidence=config[\"alpha\"][0],\n",
    "            alpha_localization=config[\"alpha\"][1],\n",
    "            alpha_classification=config[\"alpha\"][2],\n",
    "        )\n",
    "\n",
    "        conformal_preds_cal = conf.conformalize(\n",
    "            preds_cal, parameters=parameters\n",
    "        )\n",
    "\n",
    "        results_cal = conf.evaluate(\n",
    "            preds_cal,\n",
    "            parameters=parameters,\n",
    "            conformalized_predictions=conformal_preds_cal,\n",
    "            include_confidence_in_global=False,\n",
    "        )\n",
    "\n",
    "        conformal_preds = conf.conformalize(preds_val, parameters=parameters)\n",
    "\n",
    "        results_val = conf.evaluate(\n",
    "            preds_val,\n",
    "            parameters=parameters,\n",
    "            conformalized_predictions=conformal_preds,\n",
    "            include_confidence_in_global=False,\n",
    "        )\n",
    "\n",
    "        config_str = f\"alpha-{config['alpha']}-{config['matching_function']}_{config['confidence_method']}_{config['localization_method']}_{config['classification_prediction_set']}_{config['localization_prediction_set']}\"\n",
    "\n",
    "        results[config_str] = results_val\n",
    "\n",
    "        print(f\"Results for config {config_str}:\")\n",
    "        print(f\"  {results_val}\")\n",
    "        # Save results to a pickle file\n",
    "    except Exception as e:\n",
    "        print(f\"Error with config {config}: {e}\")\n",
    "        print(traceback.format_exc())\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8e5ef31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-15 15:53:04:INFO:models.py:models:30 - __init__ ] Model detr_resnet50 initialized\n",
      "Using cache found in /home/leo.andeol/.cache/torch/hub/facebookresearch_detr_main\n",
      "[2025-04-15 15:53:06:INFO:models.py:models:76 - _load_preds_if_exists ] Loading predictions from ./saved_predictions/2c92d1aaa0cc2db665dc992cc2c004015b949d723cda785c3c3a140ebe8a808b.pkl\n",
      "[2025-04-15 15:53:06:INFO:models.py:models:76 - _load_preds_if_exists ] Loading predictions from ./saved_predictions/27b7022a01eb9f119e53d0e6c2c7e9a25a4444c25cea01599ce79e2a14f06cd0.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(data) = 5000\n",
      "len(data_cal) = 400\n",
      "len(data_val) = 400\n",
      "Predictions already exist, loading them...\n",
      "Predictions already exist, loading them...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-15 15:53:06:WARNING:cp.py:cp:1488 - __init__ ] No multiple_testing_correction provided, assuming no correction is needed. The explicit list of alphas is expected for calibration.\n",
      "[2025-04-15 15:53:06:INFO:cp.py:cp:192 - __init__ ] Defaulting to CRC backend\n",
      "[2025-04-15 15:53:06:INFO:cp.py:cp:1031 - __init__ ] Defaulting to CRC backend\n",
      "[2025-04-15 15:53:06:INFO:cp.py:cp:1728 - calibrate ] Calibrating Confidence Conformalizer\n",
      "[2025-04-15 15:53:06:DEBUG:cp.py:cp:822 - calibrate ] Optimizing for lambda_plus\n",
      "100%|██████████| 400/400 [00:00<00:00, 1388.00it/s]\n",
      "[2025-04-15 15:53:06:DEBUG:optim.py:optim:200 - optimize ] Risk after 1st epoch is 0.004987531341612339 < 0.03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First risk: 0.004987531341612339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.9082438945770264. Corrected Risk = 0.0324:  50%|████▉     | 6573/13249 [00:13<00:14, 454.66it/s][2025-04-15 15:53:19:INFO:optim.py:optim:378 - optimize ] Solution Found: 0.9082794785499573 with risk 0.03241895139217377\n",
      "0.9082438945770264. Corrected Risk = 0.0324:  50%|████▉     | 6585/13249 [00:13<00:13, 498.23it/s]\n",
      "[2025-04-15 15:53:19:DEBUG:cp.py:cp:836 - calibrate ] Optimizing for lambda_minus\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "All risks raw (precomputed):\n",
      "Confidence Risk: 0.029925186187028885\n",
      "Localization Risk: 0.0024937656708061695\n",
      "Classification Risk: 0.0024937656708061695\n",
      "Max Risk: 0.029925186187028885\n",
      "All risks monotonized (precomputed):\n",
      "Confidence Risk: 0.029925186187028885\n",
      "Localization Risk: 0.0024937656708061695\n",
      "Classification Risk: 0.0024937656708061695\n",
      "Max Risk: 0.029925186187028885\n",
      "Confidence risk (recomputed):\n",
      "Confidence Risk: 0.05249999836087227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [00:00<00:00, 1391.23it/s]\n",
      "[2025-04-15 15:53:20:DEBUG:optim.py:optim:200 - optimize ] Risk after 1st epoch is 0.0024937656708061695 < 0.03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First risk: 0.0024937656708061695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.9037179350852966. Corrected Risk = 0.0324:  50%|█████     | 6662/13249 [00:12<00:14, 458.16it/s][2025-04-15 15:53:33:INFO:optim.py:optim:378 - optimize ] Solution Found: 0.9038084745407104 with risk 0.03241895139217377\n",
      "0.9037179350852966. Corrected Risk = 0.0324:  50%|█████     | 6681/13249 [00:12<00:12, 523.24it/s]\n",
      "[2025-04-15 15:53:33:INFO:cp.py:cp:1738 - calibrate ] Setting Confidence Threshold of Predictions\n",
      "[2025-04-15 15:53:33:INFO:cp.py:cp:1749 - calibrate ] Calibrated Confidence λ : 0.9083\n",
      "\t and associated Confidence Threshold : 0.09172052145004272\n",
      "[2025-04-15 15:53:33:INFO:cp.py:cp:1764 - calibrate ] Matching Predictions to True Boxes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "All risks raw (precomputed):\n",
      "Confidence Risk: 0.029925186187028885\n",
      "Localization Risk: 0.0\n",
      "Classification Risk: 0.0\n",
      "Max Risk: 0.029925186187028885\n",
      "All risks monotonized (precomputed):\n",
      "Confidence Risk: 0.029925186187028885\n",
      "Localization Risk: 0.0\n",
      "Classification Risk: 0.0\n",
      "Max Risk: 0.029925186187028885\n",
      "Confidence risk (recomputed):\n",
      "Confidence Risk: 0.05249999836087227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "400it [00:00, 8065.04it/s]\n",
      "[2025-04-15 15:53:33:INFO:cp.py:cp:1777 - calibrate ] Calibrating Localization Conformalizer\n",
      "[2025-04-15 15:53:33:INFO:cp.py:cp:464 - calibrate ] Using overload confidence threshold: 0.0962\n",
      "[0.00, 250.00] -> 125.0. Corrected Risk = 0.01:  23%|██▎       | 3/13 [00:11<00:39,  3.98s/it] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 120\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    104\u001b[0m     conf \u001b[38;5;241m=\u001b[39m ODConformalizer(\n\u001b[1;32m    105\u001b[0m         guarantee_level\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    106\u001b[0m         matching_function\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmatching_function\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    117\u001b[0m         optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary_search\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    118\u001b[0m     )\n\u001b[0;32m--> 120\u001b[0m     parameters \u001b[38;5;241m=\u001b[39m \u001b[43mconf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalibrate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreds_cal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m        \u001b[49m\u001b[43malpha_confidence\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43malpha\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m        \u001b[49m\u001b[43malpha_localization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43malpha\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m        \u001b[49m\u001b[43malpha_classification\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43malpha\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    127\u001b[0m     conformal_preds_cal \u001b[38;5;241m=\u001b[39m conf\u001b[38;5;241m.\u001b[39mconformalize(\n\u001b[1;32m    128\u001b[0m         preds_cal, parameters\u001b[38;5;241m=\u001b[39mparameters\n\u001b[1;32m    129\u001b[0m     )\n\u001b[1;32m    131\u001b[0m     results_cal \u001b[38;5;241m=\u001b[39m conf\u001b[38;5;241m.\u001b[39mevaluate(\n\u001b[1;32m    132\u001b[0m         preds_cal,\n\u001b[1;32m    133\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[1;32m    134\u001b[0m         conformalized_predictions\u001b[38;5;241m=\u001b[39mconformal_preds_cal,\n\u001b[1;32m    135\u001b[0m         include_confidence_in_global\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    136\u001b[0m     )\n",
      "File \u001b[0;32m~/envs/cods_13/cods/cods/od/cp.py:1779\u001b[0m, in \u001b[0;36mODConformalizer.calibrate\u001b[0;34m(self, predictions, global_alpha, alpha_confidence, alpha_localization, alpha_classification, verbose)\u001b[0m\n\u001b[1;32m   1776\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[1;32m   1777\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCalibrating Localization Conformalizer\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1779\u001b[0m lambda_localization \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlocalization_conformalizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalibrate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1780\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1781\u001b[0m \u001b[43m    \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malpha_localization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1782\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1783\u001b[0m \u001b[43m    \u001b[49m\u001b[43moverload_confidence_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimistic_confidence_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1784\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1786\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[1;32m   1787\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m   1788\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCalibrated Localization λ : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlambda_localization\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1789\u001b[0m     )\n",
      "File \u001b[0;32m~/envs/cods_13/cods/cods/od/cp.py:489\u001b[0m, in \u001b[0;36mLocalizationConformalizer.calibrate\u001b[0;34m(self, predictions, alpha, steps, bounds, verbose, overload_confidence_threshold)\u001b[0m\n\u001b[1;32m    486\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m conf_boxes, conf_cls\n\u001b[1;32m    488\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer2 \u001b[38;5;241m=\u001b[39m SecondStepMonotonizingOptimizer()\n\u001b[0;32m--> 489\u001b[0m     lambda_localization \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbuild_predictions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmatching_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatching_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mB\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprediction_set\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43madditive\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m13\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-9\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    505\u001b[0m     \u001b[38;5;66;03m# objective_function = self._get_objective_function(\u001b[39;00m\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;66;03m#     predictions=predictions,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;66;03m#     verbose=verbose,\u001b[39;00m\n\u001b[1;32m    517\u001b[0m     \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[1;32m    518\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/envs/cods_13/cods/cods/od/optim.py:675\u001b[0m, in \u001b[0;36mSecondStepMonotonizingOptimizer.optimize\u001b[0;34m(self, predictions, build_predictions, loss, matching_function, alpha, device, B, bounds, steps, epsilon, verbose)\u001b[0m\n\u001b[1;32m    671\u001b[0m pbar \u001b[38;5;241m=\u001b[39m tqdm(\u001b[38;5;28mrange\u001b[39m(steps), disable\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m verbose)\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m pbar:\n\u001b[1;32m    674\u001b[0m     \u001b[38;5;66;03m# Evaluating the risk in this lbd, requires to remonotonize the loss in this lbd_loc/cls wrt the lbd_cnf\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     risk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate_risk\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlbd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlambda_conf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    680\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbuild_predictions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmatching_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    684\u001b[0m     corrected_risk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_correct_risk(risk, \u001b[38;5;28mlen\u001b[39m(predictions), B)\n\u001b[1;32m    686\u001b[0m     corrected_risk \u001b[38;5;241m=\u001b[39m corrected_risk\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/envs/cods_13/cods/cods/od/optim.py:606\u001b[0m, in \u001b[0;36mSecondStepMonotonizingOptimizer.evaluate_risk\u001b[0;34m(self, lbd, loss, final_lbd_conf, predictions, build_predictions, matching_function)\u001b[0m\n\u001b[1;32m    599\u001b[0m \u001b[38;5;66;03m# print(matched_pred_boxes_i.shape)\u001b[39;00m\n\u001b[1;32m    600\u001b[0m \u001b[38;5;66;03m# print(matched_pred_boxes_i)\u001b[39;00m\n\u001b[1;32m    602\u001b[0m matched_conf_boxes_i, matched_conf_cls_i \u001b[38;5;241m=\u001b[39m build_predictions(\n\u001b[1;32m    603\u001b[0m     matched_pred_boxes_i, matched_pred_cls_i, lbd\n\u001b[1;32m    604\u001b[0m )\n\u001b[0;32m--> 606\u001b[0m loss_i \u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrue_boxes_i\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrue_cls_i\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmatched_conf_boxes_i\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmatched_conf_cls_i\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    611\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    613\u001b[0m old_loss_i \u001b[38;5;241m=\u001b[39m losses[i]\n\u001b[1;32m    614\u001b[0m losses[i] \u001b[38;5;241m=\u001b[39m loss_i\n",
      "File \u001b[0;32m~/envs/cods_13/cods/cods/od/loss.py:642\u001b[0m, in \u001b[0;36mPixelWiseRecallLoss.__call__\u001b[0;34m(self, true_boxes, true_cls, conf_boxes, conf_cls)\u001b[0m\n\u001b[1;32m    640\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mones(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    641\u001b[0m areas \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_covered_areas(conf_boxes, true_boxes)\n\u001b[0;32m--> 642\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice) \u001b[38;5;241m-\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(areas)\n\u001b[1;32m    643\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "import pickle\n",
    "import traceback\n",
    "from itertools import product\n",
    "\n",
    "from cods.od.cp import ODConformalizer\n",
    "from cods.od.data import MSCOCODataset\n",
    "from cods.od.models import DETRModel\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"  # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = (\n",
    "    \"0\"  # chose the GPU. If only one, then \"0\"\n",
    ")\n",
    "\n",
    "logging.getLogger().setLevel(logging.DEBUG)\n",
    "\n",
    "# set [COCO_PATH] to the directory to your local copy of the COCO dataset\n",
    "COCO_PATH = \"/datasets/shared_datasets/coco/\"\n",
    "\n",
    "data = MSCOCODataset(root=COCO_PATH, split=\"val\")\n",
    "\n",
    "calibration_ratio = (\n",
    "    0.5  # set 0.5 to use 50% for calibration and 50% for testing\n",
    ")\n",
    "\n",
    "use_smaller_subset = True  # TODO: Temp\n",
    "\n",
    "if use_smaller_subset:\n",
    "    data_cal, data_val = data.split_dataset(\n",
    "        calibration_ratio, shuffle=False, n_calib_test=800\n",
    "    )\n",
    "else:\n",
    "    data_cal, data_val = data.split_dataset(calibration_ratio, shuffle=True)\n",
    "\n",
    "# model and weights are downloaded from https://github.com/facebookresearch/detr\n",
    "model = DETRModel(model_name=\"detr_resnet50\", pretrained=True, device=\"cpu\")\n",
    "# model = YOLOModel(model_name=\"yolov8x.pt\", pretrained=True)\n",
    "\n",
    "\n",
    "print(f\"{len(data) = }\")\n",
    "print(f\"{len(data_cal) = }\")\n",
    "print(f\"{len(data_val) = }\")\n",
    "\n",
    "preds_cal = model.build_predictions(\n",
    "    data_cal,\n",
    "    dataset_name=\"mscoco\",\n",
    "    split_name=\"cal\",\n",
    "    batch_size=12,\n",
    "    collate_fn=data._collate_fn,  # TODO: make this a default for COCO\n",
    "    shuffle=False,\n",
    "    force_recompute=False,  # False,\n",
    "    deletion_method=\"nms\",\n",
    "    filter_preds_by_confidence=1e-3,\n",
    ")\n",
    "preds_val = model.build_predictions(\n",
    "    data_val,\n",
    "    dataset_name=\"mscoco\",\n",
    "    split_name=\"test\",\n",
    "    batch_size=12,\n",
    "    collate_fn=data._collate_fn,\n",
    "    shuffle=False,\n",
    "    force_recompute=False,  # False,\n",
    "    deletion_method=\"nms\",\n",
    "    filter_preds_by_confidence=1e-3,\n",
    ")\n",
    "\n",
    "results = {}\n",
    "\n",
    "alphas = [[0.03, 0.1, 0.1]]\n",
    "matching_functions = [\"mix\"]  # , \"hausdorff\", \"lac\"]#[\"giou\", \"hausdorff\"]\n",
    "confidence_methods = [\n",
    "    \"box_count_threshold\",\n",
    "    # \"box_count_recall\",\n",
    "    # \"box_thresholded_distance\",\n",
    "]\n",
    "localization_methods = [\"pixelwise\"]  # , \"boxwise\"]\n",
    "classification_prediction_sets = [\"aps\"]\n",
    "localization_prediction_sets = [\"additive\"]  # , \"multiplicative\"]\n",
    "\n",
    "configs = []\n",
    "for alpha in alphas:\n",
    "    for matching_function in matching_functions:\n",
    "        for confidence_method in confidence_methods:\n",
    "            for localization_method in localization_methods:\n",
    "                for (\n",
    "                    classification_prediction_set\n",
    "                ) in classification_prediction_sets:\n",
    "                    for (\n",
    "                        localization_prediction_set\n",
    "                    ) in localization_prediction_sets:\n",
    "                        configs.append(\n",
    "                            {\n",
    "                                \"alpha\": alpha,\n",
    "                                \"matching_function\": matching_function,\n",
    "                                \"confidence_method\": confidence_method,\n",
    "                                \"localization_method\": localization_method,\n",
    "                                \"classification_prediction_set\": classification_prediction_set,\n",
    "                                \"localization_prediction_set\": localization_prediction_set,\n",
    "                            }\n",
    "                        )\n",
    "for config in configs:\n",
    "    try:\n",
    "        conf = ODConformalizer(\n",
    "            guarantee_level=\"image\",\n",
    "            matching_function=config[\"matching_function\"],\n",
    "            multiple_testing_correction=None,\n",
    "            confidence_method=config[\"confidence_method\"],\n",
    "            #confidence_threshold=0.1,\n",
    "            localization_method=config[\"localization_method\"],\n",
    "            localization_prediction_set=config[\"localization_prediction_set\"],\n",
    "            classification_method=\"binary\",\n",
    "            classification_prediction_set=config[\n",
    "                \"classification_prediction_set\"\n",
    "            ],\n",
    "            backend=\"auto\",\n",
    "            optimizer=\"binary_search\",\n",
    "        )\n",
    "\n",
    "        parameters = conf.calibrate(\n",
    "            preds_cal,\n",
    "            alpha_confidence=config[\"alpha\"][0],\n",
    "            alpha_localization=config[\"alpha\"][1],\n",
    "            alpha_classification=config[\"alpha\"][2],\n",
    "        )\n",
    "\n",
    "        conformal_preds_cal = conf.conformalize(\n",
    "            preds_cal, parameters=parameters\n",
    "        )\n",
    "\n",
    "        results_cal = conf.evaluate(\n",
    "            preds_cal,\n",
    "            parameters=parameters,\n",
    "            conformalized_predictions=conformal_preds_cal,\n",
    "            include_confidence_in_global=False,\n",
    "        )\n",
    "\n",
    "        conformal_preds = conf.conformalize(preds_val, parameters=parameters)\n",
    "\n",
    "        results_val = conf.evaluate(\n",
    "            preds_val,\n",
    "            parameters=parameters,\n",
    "            conformalized_predictions=conformal_preds,\n",
    "            include_confidence_in_global=False,\n",
    "        )\n",
    "\n",
    "        config_str = f\"alpha-{config['alpha']}-{config['matching_function']}_{config['confidence_method']}_{config['localization_method']}_{config['classification_prediction_set']}_{config['localization_prediction_set']}\"\n",
    "\n",
    "        results[config_str] = results_val\n",
    "\n",
    "        print(f\"Results for config {config_str}:\")\n",
    "        print(f\"  {results_val}\")\n",
    "        # Save results to a pickle file\n",
    "    except Exception as e:\n",
    "        print(f\"Error with config {config}: {e}\")\n",
    "        print(traceback.format_exc())\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219d3b31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
