{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conformal Object Detection: first steps\n",
    "\n",
    "This tutorial should get you started doing **Conformal Object Detection (COD)** with the [`cods`](https://github.com/leoandeol/cods) library.\n",
    "\n",
    "For more information on the methods implemented in CODS, see the papers: \n",
    "- [AndÃ©ol et al. 2023: Confident Object Detection via Conformal Prediction and Conformal Risk Control](https://proceedings.mlr.press/v204/andeol23a.html)\n",
    "- [Angelopoulos et al. 2022: Conformal Risk Control](https://arxiv.org/abs/2208.02814)\n",
    "- [Li et al. 2022: Towards PAC Multi-Object Detection and Tracking](https://arxiv.org/abs/2204.07482)\n",
    "- [Bates et al. 2021: Risk Controlling Prediction Sets](https://dl.acm.org/doi/abs/10.1145/3478535)\n",
    "\n",
    "\n",
    "### Get started\n",
    "1. Download the MS-COCO dataset: \n",
    "    - https://cocodataset.org/\n",
    "2. Download DETR: automatically via Pytorch hub: https://pytorch.org/hub/\n",
    "    - source: https://github.com/facebookresearch/detr\n",
    "\n",
    "### Contents\n",
    "What we will be doing:\n",
    "1. Setup inference [â¤µ](#Setup-inferences)\n",
    "    - load predictor (DETR) pretrained on COCO\n",
    "    - Split the validation into: calibration & validation dataset\n",
    "2. Run inferences on these datasets [â¤µ](#Setup-inferences)\n",
    "    - Save predictions to disk: faster than re-predict for every test\n",
    "3. Test Conformal Prediction !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cods.od.data import MSCOCODataset\n",
    "from cods.od.models import YOLOModel, DETRModel\n",
    "import logging\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"  # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = (\n",
    "    \"1\"  # chose the GPU. If only one, then \"0\"\n",
    ")\n",
    "\n",
    "logging.getLogger().setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setup inferences [ðŸ”](#conformal-object-detection-first-steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set [COCO_PATH] to the directory to your local copy of the COCO dataset\n",
    "COCO_PATH = \"/datasets/shared_datasets/coco/\"\n",
    "\n",
    "data = MSCOCODataset(root=COCO_PATH, split=\"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/leo.andeol/.cache/torch/hub/facebookresearch_detr_main\n",
      "/home/leo.andeol/envs/cods_13/cods/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/leo.andeol/envs/cods_13/cods/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(data) = 5000\n",
      "len(data_cal) = 400\n",
      "len(data_val) = 400\n"
     ]
    }
   ],
   "source": [
    "calibration_ratio = (\n",
    "    0.5  # set 0.5 to use 50% for calibration and 50% for testing\n",
    ")\n",
    "\n",
    "use_smaller_subset = True  # TODO: Temp\n",
    "\n",
    "if use_smaller_subset:\n",
    "    data_cal, data_val = data.split_dataset(\n",
    "        calibration_ratio, shuffle=False, n_calib_test=800\n",
    "    )\n",
    "else:\n",
    "    data_cal, data_val = data.split_dataset(calibration_ratio, shuffle=False)\n",
    "\n",
    "# model and weights are downloaded from https://github.com/facebookresearch/detr\n",
    "model = DETRModel(model_name=\"detr_resnet50\", pretrained=True, device=\"cpu\")\n",
    "# model = YOLOModel(model_name=\"yolov8x.pt\", pretrained=True)\n",
    "\n",
    "\n",
    "print(f\"{len(data) = }\")\n",
    "print(f\"{len(data_cal) = }\")\n",
    "print(f\"{len(data_val) = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run inferences:\n",
    "- the first time, run inferences and save them disk\n",
    "- if predictions are saved on disk, load them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading predictions from ./saved_predictions/2c92d1aaa0cc2db665dc992cc2c004015b949d723cda785c3c3a140ebe8a808b.pkl\n",
      "Predictions already exist, loading them...\n",
      "Loading predictions from ./saved_predictions/27b7022a01eb9f119e53d0e6c2c7e9a25a4444c25cea01599ce79e2a14f06cd0.pkl\n",
      "Predictions already exist, loading them...\n"
     ]
    }
   ],
   "source": [
    "preds_cal = model.build_predictions(\n",
    "    data_cal,\n",
    "    dataset_name=\"mscoco\",\n",
    "    split_name=\"cal\",\n",
    "    batch_size=12,\n",
    "    collate_fn=data._collate_fn,  # TODO: make this a default for COCO\n",
    "    shuffle=False,\n",
    "    force_recompute=False,  # False,\n",
    "    deletion_method=\"nms\",\n",
    ")\n",
    "preds_val = model.build_predictions(\n",
    "    data_val,\n",
    "    dataset_name=\"mscoco\",\n",
    "    split_name=\"test\",\n",
    "    batch_size=12,\n",
    "    collate_fn=data._collate_fn,\n",
    "    shuffle=False,\n",
    "    force_recompute=False,  # False,\n",
    "    deletion_method=\"nms\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cods.od.cp import ODConformalizer\n",
    "from cods.od.loss import (\n",
    "    PixelWiseRecallLoss,\n",
    "    ClassificationLossWrapper,\n",
    "    ODBinaryClassificationLoss,\n",
    ")\n",
    "from cods.od.data import ODParameters, ODConformalizedPredictions\n",
    "from cods.od.utils import (\n",
    "    generalized_iou,\n",
    "    compute_risk_image_level,\n",
    "    match_predictions_to_true_boxes,\n",
    "    apply_margins,\n",
    ")\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "scs = np.linspace(0, 1, 20)\n",
    "lbd_loc = 0\n",
    "lbd_cls = 0\n",
    "\n",
    "pred_cls = preds_cal.pred_cls\n",
    "true_cls = preds_cal.true_cls\n",
    "pred_boxes = preds_cal.pred_boxes\n",
    "true_boxes = preds_cal.true_boxes\n",
    "\n",
    "loc_loss_f = PixelWiseRecallLoss()\n",
    "_loss = ODBinaryClassificationLoss()\n",
    "cls_loss_f = ClassificationLossWrapper(_loss)\n",
    "\n",
    "cls_lbds = 1 - np.logspace(-6, 1, 20)\n",
    "loc_lbds = np.linspace(0, 300, 20)\n",
    "\n",
    "results_loc = {}\n",
    "results_cls = {}\n",
    "# TODO(leo): mÃ©trique monotonization\n",
    "# TODO(leo): gÃ©nÃ©rer pdf avec des paires images, et courbes en loc et cls\n",
    "\n",
    "for cls_lbd, loc_lbd in tqdm(zip(cls_lbds, loc_lbds)):\n",
    "    res_loc = []\n",
    "    res_cls = []\n",
    "    for confi in scs:\n",
    "        match_predictions_to_true_boxes(\n",
    "            preds_cal,\n",
    "            distance_function=\"hausdorff\",\n",
    "            verbose=False,\n",
    "            overload_confidence_threshold=confi,\n",
    "        )\n",
    "\n",
    "        conf_boxes = apply_margins(preds_cal.pred_boxes, loc_lbd)\n",
    "        conf_cls = [\n",
    "            [torch.where(cli >= 1 - cls_lbd)[0] for cli in cl]\n",
    "            for cl in preds_cal.pred_cls\n",
    "        ]\n",
    "\n",
    "        tmp_parameters = ODParameters(\n",
    "            global_alpha=None,\n",
    "            confidence_threshold=confi,\n",
    "            predictions_id=preds_cal.unique_id,\n",
    "        )\n",
    "        tmp_conformalized_predictions = ODConformalizedPredictions(\n",
    "            predictions=preds_cal,\n",
    "            parameters=tmp_parameters,\n",
    "            conf_boxes=conf_boxes,\n",
    "            conf_cls=conf_cls,\n",
    "        )\n",
    "        # TODO(leo): cannot do that with with object level or can I ?\n",
    "        # TODO(leoandeol): classwise risk ????\n",
    "        loc_loss = compute_risk_image_level(\n",
    "            tmp_conformalized_predictions,\n",
    "            preds_cal,\n",
    "            loc_loss_f,\n",
    "            return_list=True,\n",
    "        )\n",
    "\n",
    "        cls_loss = compute_risk_image_level(\n",
    "            tmp_conformalized_predictions,\n",
    "            preds_cal,\n",
    "            cls_loss_f,\n",
    "            return_list=True,\n",
    "        )\n",
    "\n",
    "        res_loc.append(loc_loss)\n",
    "        res_cls.append(cls_loss)\n",
    "\n",
    "    results_loc[f\"{loc_lbd}\"] = res_loc\n",
    "    results_cls[f\"{cls_lbd}\"] = res_cls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = scs\n",
    "for k, v in results_loc.items():\n",
    "    plt.plot(x, [vv.mean() for vv in v], label=f\"{int(float(k))}\")\n",
    "plt.xlabel(f\"Confidence Threshold\")\n",
    "plt.ylabel(f\"Loss value\")\n",
    "plt.title(\"Localization\")\n",
    "plt.yscale(\"log\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = scs\n",
    "for k, v in results_cls.items():\n",
    "    plt.plot(x, [vv[2].mean() for vv in v], label=f\"{float(k):.5f}\")\n",
    "plt.xlabel(f\"Confidence Threshold\")\n",
    "plt.ylabel(f\"Loss value\")\n",
    "plt.title(\"Classification\")\n",
    "plt.yscale(\"log\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Per Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in results_loc.items():\n",
    "    plt.plot(scs, [vv[idx] for vv in v], label=f\"{int(float(k))}\")\n",
    "plt.xlabel(f\"Confidence Threshold\")\n",
    "plt.ylabel(f\"Loss value\")\n",
    "plt.title(\"Localization\")\n",
    "plt.yscale(\"log\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in results_cls.items():\n",
    "    plt.plot(scs, [vv[idx] for vv in v], label=f\"{int(float(k))}\")\n",
    "plt.xlabel(f\"Confidence Threshold\")\n",
    "plt.ylabel(f\"Loss value\")\n",
    "plt.title(\"Classification\")\n",
    "plt.yscale(\"log\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_plot(idx, plot_type):\n",
    "    \"\"\"\n",
    "    Generates a matplotlib plot for the given image.\n",
    "\n",
    "    Args:\n",
    "        image: PIL Image object.\n",
    "        plot_type: Type of plot to generate (1 or 2).\n",
    "\n",
    "    Returns:\n",
    "        Matplotlib figure object.\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(4, 3))\n",
    "    if plot_type == \"lox\":\n",
    "        for k, v in results_loc.items():\n",
    "            ax.plot(scs, [vv[idx] for vv in v], label=f\"{int(float(k))}\")\n",
    "        ax.set_xlabel(\"Confidence Threshold\")  # Correct method\n",
    "        ax.set_ylabel(\"Loss Value\")  # Correct method\n",
    "        ax.set_title(\"Localization\")  # Correct method\n",
    "        ax.set_yscale(\"log\")  # Set y-axis to log scale\n",
    "        ax.legend()\n",
    "    elif plot_type == \"cls\":\n",
    "        for k, v in results_cls.items():\n",
    "            ax.plot(scs, [vv[idx] for vv in v], label=f\"{float(k):.4f}\")\n",
    "        ax.set_xlabel(\"Confidence Threshold\")  # Correct method\n",
    "        ax.set_ylabel(\"Loss Value\")  # Correct method\n",
    "        ax.set_title(\"Classification\")  # Correct method\n",
    "        ax.set_yscale(\"log\")\n",
    "        ax.legend()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reportlab.pdfgen import canvas\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.lib.utils import ImageReader\n",
    "from reportlab.pdfbase.ttfonts import TTFont\n",
    "from reportlab.pdfbase import pdfmetrics\n",
    "from reportlab.lib.units import inch\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "import math\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def create_dataset_pdf_with_plots(\n",
    "    predictions,\n",
    "    output_filename=\"monotonicity_plot_with_images.pdf\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Creates a PDF displaying rows of three images (one loaded image and two plots) on each page.\n",
    "\n",
    "    Args:\n",
    "        predictions: An object with attribute `image_paths` containing paths to the images.\n",
    "        generate_plot: A function that generates matplotlib plots based on image data.\n",
    "        output_filename: Name of the output PDF file.\n",
    "    \"\"\"\n",
    "\n",
    "    # Set up the PDF canvas\n",
    "    c = canvas.Canvas(output_filename, pagesize=letter)\n",
    "    width, height = letter\n",
    "\n",
    "    # Register a default font\n",
    "    pdfmetrics.registerFont(TTFont(\"Monospace\", \"monospace.medium.ttf\"))\n",
    "\n",
    "    # Calculate positions for the three images per row\n",
    "    row_height = (height - 2 * inch) / 2\n",
    "    image_width = (width - 4 * inch) / 3  # One row with three columns\n",
    "    image_height = row_height * 0.8  # Reserve some space for titles\n",
    "\n",
    "    # Positions for three items per row\n",
    "    positions = [\n",
    "        (1 * inch, height - 1.5 * inch - row_height),  # Top row: Image\n",
    "        (\n",
    "            1 * inch + image_width + 1 * inch,\n",
    "            height - 1.5 * inch - row_height,\n",
    "        ),  # Top row: Plot 1\n",
    "        (\n",
    "            1 * inch + 2 * (image_width + 1 * inch),\n",
    "            height - 1.5 * inch - row_height,\n",
    "        ),  # Top row: Plot 2\n",
    "        (1 * inch, height - 2.5 * inch - 2 * row_height),  # Bottom row: Image\n",
    "        (\n",
    "            1 * inch + image_width + 1 * inch,\n",
    "            height - 2.5 * inch - 2 * row_height,\n",
    "        ),  # Bottom row: Plot 1\n",
    "        (\n",
    "            1 * inch + 2 * (image_width + 1 * inch),\n",
    "            height - 2.5 * inch - 2 * row_height,\n",
    "        ),  # Bottom row: Plot 2\n",
    "    ]\n",
    "\n",
    "    image_count = 0\n",
    "\n",
    "    for i, path in tqdm(enumerate(predictions.image_paths)):\n",
    "        # Load image\n",
    "        img = Image.open(path)\n",
    "\n",
    "        # Convert image to bytes\n",
    "        img_byte_arr = io.BytesIO()\n",
    "        img.save(img_byte_arr, format=\"JPEG\")\n",
    "        img_byte_arr = img_byte_arr.getvalue()\n",
    "\n",
    "        # Create an ImageReader object\n",
    "        img_reader = ImageReader(io.BytesIO(img_byte_arr))\n",
    "\n",
    "        # Generate two plots\n",
    "        plot1 = generate_plot(i, plot_type=\"loc\")\n",
    "        plot2 = generate_plot(i, plot_type=\"cls\")\n",
    "\n",
    "        # Convert plots to bytes\n",
    "        plot1_buf = io.BytesIO()\n",
    "        plot1.savefig(plot1_buf, format=\"PNG\", bbox_inches=\"tight\")\n",
    "        plot1_buf.seek(0)\n",
    "        plot1_reader = ImageReader(plot1_buf)\n",
    "\n",
    "        plot2_buf = io.BytesIO()\n",
    "        plot2.savefig(plot2_buf, format=\"PNG\", bbox_inches=\"tight\")\n",
    "        plot2_buf.seek(0)\n",
    "        plot2_reader = ImageReader(plot2_buf)\n",
    "\n",
    "        # Get positions\n",
    "        pos_image = positions[(image_count % 6) // 3 * 3]\n",
    "        pos_plot1 = positions[(image_count % 6) // 3 * 3 + 1]\n",
    "        pos_plot2 = positions[(image_count % 6) // 3 * 3 + 2]\n",
    "\n",
    "        # Draw the images and plots\n",
    "        c.drawImage(\n",
    "            img_reader,\n",
    "            pos_image[0],\n",
    "            pos_image[1],\n",
    "            width=image_width,\n",
    "            height=image_height,\n",
    "        )\n",
    "        c.drawImage(\n",
    "            plot1_reader,\n",
    "            pos_plot1[0],\n",
    "            pos_plot1[1],\n",
    "            width=image_width,\n",
    "            height=image_height,\n",
    "        )\n",
    "        c.drawImage(\n",
    "            plot2_reader,\n",
    "            pos_plot2[0],\n",
    "            pos_plot2[1],\n",
    "            width=image_width,\n",
    "            height=image_height,\n",
    "        )\n",
    "\n",
    "        # Add title for the loaded image\n",
    "        title = os.path.basename(path)\n",
    "        c.setFont(\"Monospace\", 8)\n",
    "        c.drawString(pos_image[0], pos_image[1] - 0.2 * inch, title)\n",
    "\n",
    "        image_count += 1\n",
    "\n",
    "        # Start a new page if six images (two rows) are filled\n",
    "        if image_count % 6 == 0:\n",
    "            c.showPage()\n",
    "\n",
    "    # Save the PDF\n",
    "    c.save()\n",
    "\n",
    "    print(\n",
    "        f\"PDF created with {image_count} images (each with two plots) on {math.ceil(image_count / 6)} pages.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:02,  3.95it/s]/tmp/ipykernel_4180720/2645542788.py:15: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  fig, ax = plt.subplots(figsize=(4, 3))\n",
      "25it [00:06,  4.02it/s]/tmp/ipykernel_4180720/2645542788.py:30: UserWarning: Data has no positive values, and therefore cannot be log-scaled.\n",
      "  ax.set_yscale(\"log\")\n",
      "400it [01:51,  3.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF created with 400 images (each with two plots) on 67 pages.\n"
     ]
    }
   ],
   "source": [
    "create_dataset_pdf_with_plots(\n",
    "    preds_cal,\n",
    "    output_filename=\"monotonicity_HAUSDORFF.pdf\",\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
